{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81eb1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cwd = Path(os.getcwd())\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == \"notebooks\" else cwd\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "\n",
    "def descargar_datos_bigquery_histórico():\n",
    "    \"\"\"\n",
    "    Descarga y concatena datos históricos de ventas desde BigQuery.\n",
    "    - La primera tabla contiene datos desde 2023 hasta junio de 2025.\n",
    "    - La segunda tabla contiene datos desde julio de 2025 en adelante.\n",
    "    El archivo se guarda en data/raw con la fecha del último domingo con datos como nomenclatura.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    print(\"Iniciando conexión con BigQuery...\")\n",
    "    client = bigquery.Client()\n",
    "    print(\"Conexión establecida.\")\n",
    "\n",
    "    # Descargar datos históricos hasta junio 2025\n",
    "    query1 = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `fleca-del-port.varios.raw_data_bq_forecasting_20250630`\n",
    "    \"\"\"\n",
    "    df1 = client.query(query1).to_dataframe()\n",
    "\n",
    "    # Descargar datos desde julio 2025 en adelante\n",
    "    query2 = \"\"\"\n",
    "    SELECT \n",
    "        fecha, n_factura, zona_de_venta, producto, familia, cantidad, base_imponible, tipo_IVA, total\n",
    "    FROM `fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023`\n",
    "    WHERE fecha >= '2025-07-01'\n",
    "    \"\"\"\n",
    "    df2 = client.query(query2).to_dataframe()\n",
    "\n",
    "    # Concatenar ambos DataFrames (unión vertical)\n",
    "    df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
    "\n",
    "    # Calcular el último domingo anterior o igual a la última fecha de datos\n",
    "    if 'fecha' in df.columns:\n",
    "        fechas = pd.to_datetime(df['fecha'])\n",
    "        ultima_fecha = fechas.max()\n",
    "        ultimo_domingo = ultima_fecha - pd.Timedelta(days=(ultima_fecha.weekday() + 1) % 7)\n",
    "        fecha_nomenclatura = ultimo_domingo.strftime(\"%Y%m%d\")\n",
    "        print(f\"Rango fechas final: {fechas.min()} - {fechas.max()}\")\n",
    "    else:\n",
    "        fecha_nomenclatura = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Guardar el DataFrame combinado en la carpeta data/raw con nomenclatura de último domingo\n",
    "    output_path = RAW_DIR / f\"raw_data_bq_forecasting_{fecha_nomenclatura}.parquet\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Guardando archivo en {output_path} ...\")\n",
    "    df.to_parquet(str(output_path), index=False)\n",
    "    print(\"Archivo guardado correctamente.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c486312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando conexión con BigQuery...\n",
      "Conexión establecida.\n",
      "Conexión establecida.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango fechas final: 2023-01-02 00:00:00 - 2025-09-14 00:00:00\n",
      "Guardando archivo en c:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250914.parquet ...\n",
      "Archivo guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Descargar datos históricos. Llamar a la función\n",
    "raw_all_data = descargar_datos_bigquery_histórico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "396b4623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fecha",
         "rawType": "dbdate",
         "type": "unknown"
        },
        {
         "name": "n_factura",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "zona_de_venta",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "producto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "familia",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cantidad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "base_imponible",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tipo_IVA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "734e7768-c8bc-416d-ad0f-53ac7044a539",
       "rows": [
        [
         "373278",
         "2025-09-14",
         "T/207001",
         "LL5",
         "PETIT XOCO (UNID)",
         "BOLLERIA",
         "1.0",
         "0.91",
         "10.0",
         "1.0"
        ],
        [
         "373277",
         "2025-09-14",
         "T/206979",
         "S4",
         "PETIT XOCO (UNID)",
         "BOLLERIA",
         "1.0",
         "0.91",
         "10.0",
         "1.0"
        ],
        [
         "373276",
         "2025-09-14",
         "T/206978",
         "S4",
         "PETIT XOCO (UNID)",
         "BOLLERIA",
         "1.0",
         "0.91",
         "10.0",
         "1.0"
        ],
        [
         "373296",
         "2025-09-14",
         "T/206999",
         "T2",
         "PETIT XOCO (UNID)",
         "BOLLERIA",
         "2.0",
         "2.0",
         "10.0",
         "2.2"
        ],
        [
         "372313",
         "2025-09-14",
         "T/206959",
         "T5",
         "CAFE LLET",
         "CAFES",
         "1.0",
         "1.73",
         "10.0",
         "1.9"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>n_factura</th>\n",
       "      <th>zona_de_venta</th>\n",
       "      <th>producto</th>\n",
       "      <th>familia</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>base_imponible</th>\n",
       "      <th>tipo_IVA</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373278</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>T/207001</td>\n",
       "      <td>LL5</td>\n",
       "      <td>PETIT XOCO (UNID)</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373277</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>T/206979</td>\n",
       "      <td>S4</td>\n",
       "      <td>PETIT XOCO (UNID)</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373276</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>T/206978</td>\n",
       "      <td>S4</td>\n",
       "      <td>PETIT XOCO (UNID)</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373296</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>T/206999</td>\n",
       "      <td>T2</td>\n",
       "      <td>PETIT XOCO (UNID)</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372313</th>\n",
       "      <td>2025-09-14</td>\n",
       "      <td>T/206959</td>\n",
       "      <td>T5</td>\n",
       "      <td>CAFE LLET</td>\n",
       "      <td>CAFES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fecha n_factura zona_de_venta           producto   familia  \\\n",
       "373278  2025-09-14  T/207001           LL5  PETIT XOCO (UNID)  BOLLERIA   \n",
       "373277  2025-09-14  T/206979            S4  PETIT XOCO (UNID)  BOLLERIA   \n",
       "373276  2025-09-14  T/206978            S4  PETIT XOCO (UNID)  BOLLERIA   \n",
       "373296  2025-09-14  T/206999            T2  PETIT XOCO (UNID)  BOLLERIA   \n",
       "372313  2025-09-14  T/206959            T5          CAFE LLET     CAFES   \n",
       "\n",
       "        cantidad  base_imponible  tipo_IVA  total  \n",
       "373278       1.0            0.91      10.0    1.0  \n",
       "373277       1.0            0.91      10.0    1.0  \n",
       "373276       1.0            0.91      10.0    1.0  \n",
       "373296       2.0            2.00      10.0    2.2  \n",
       "372313       1.0            1.73      10.0    1.9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar los datos descargados\n",
    "raw_all_data_sorted = raw_all_data.sort_values('fecha')\n",
    "raw_all_data_sorted.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46abcba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando conexión con BigQuery...\n",
      "Conexión establecida.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango fechas final: 2023-01-02 00:00:00 - 2025-09-14 00:00:00\n",
      "Guardando archivo en c:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250914.parquet ...\n",
      "Archivo guardado correctamente.\n",
      "year                       int64\n",
      "week                       int64\n",
      "familia           string[python]\n",
      "base_imponible           float64\n",
      "is_summer_peak             int32\n",
      "is_easter                  int64\n",
      "dias_semana                int64\n",
      "week_start        datetime64[ns]\n",
      "dtype: object\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2023     1  BOLLERIA          825.11               0          0   \n",
      "1  2023     2  BOLLERIA          658.40               0          0   \n",
      "2  2023     3  BOLLERIA          741.40               0          0   \n",
      "3  2023     4  BOLLERIA          653.64               0          0   \n",
      "4  2023     5  BOLLERIA          680.46               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2023-01-02  \n",
      "1            7 2023-01-09  \n",
      "2            7 2023-01-16  \n",
      "3            7 2023-01-23  \n",
      "4            7 2023-01-30  \n",
      "2025-09-21 20:29:23,117 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-09-21 20:29:23,119 INFO: Initializing external client\n",
      "2025-09-21 20:29:23,119 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-21 20:29:24,320 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 137/137 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: times_series_bolleria_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/times_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "2025-09-21 20:30:10,774 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-09-21 20:30:13,999 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-09-21 20:32:06,538 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-09-21 20:32:06,700 INFO: Waiting for log aggregation to finish.\n",
      "2025-09-21 20:32:28,838 INFO: Execution finished successfully.\n",
      "Carga inicial del histórico completada.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el histórico descargado al Feature Group de Hopsworks\n",
    "from src.data_utils import transformar_a_series_temporales\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "\n",
    "# Usar el DataFrame descargado previamente\n",
    "raw_all_data = descargar_datos_bigquery_histórico()\n",
    "\n",
    "# Transformar a series temporales semanales para la familia BOLLERIA\n",
    "df_ts_historico = transformar_a_series_temporales(raw_all_data, familia=\"BOLLERIA\")\n",
    "\n",
    "# Ajustar tipos para coincidir con el schema del Feature Group\n",
    "if 'fecha' in df_ts_historico.columns:\n",
    "    df_ts_historico = df_ts_historico.drop(columns=['fecha'])\n",
    "df_ts_historico['year'] = df_ts_historico['year'].astype('int64')\n",
    "df_ts_historico['week'] = df_ts_historico['week'].astype('int64')\n",
    "df_ts_historico['familia'] = df_ts_historico['familia'].astype('string')\n",
    "df_ts_historico['base_imponible'] = df_ts_historico['base_imponible'].astype('float64')\n",
    "df_ts_historico['is_summer_peak'] = df_ts_historico['is_summer_peak'].astype('int32')\n",
    "df_ts_historico['is_easter'] = df_ts_historico['is_easter'].astype('int64')\n",
    "df_ts_historico['week_start'] = pd.to_datetime(df_ts_historico['week_start'])\n",
    "\n",
    "print(df_ts_historico.dtypes)\n",
    "print(df_ts_historico.head())\n",
    "\n",
    "# Conectar a hopsworks y al Feature Store\n",
    "project = hopsworks.login(api_key_value=config.HOPSWORKS_API_KEY, project=config.HOPSWORKS_PROJECT_NAME)\n",
    "feature_store = project.get_feature_store()\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    primary_key=[\"familia\", \"week_start\"],\n",
    "    event_time=\"week_start\"\n",
    ")\n",
    "\n",
    "# Insertar los datos históricos en el Feature Group\n",
    "feature_group.insert(\n",
    "    df_ts_historico,\n",
    "    write_options={'wait_for_job': True},\n",
    ")\n",
    "print(\"Carga inicial del histórico completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be25f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-21 20:32:28,845 INFO: Usando DataFrame de entrada: (137, 8)\n",
      "2025-09-21 20:32:28,848 INFO: Retornando DataFrame combinado: (84, 7)\n",
      "Semanas disponibles para predicción:\n",
      "    week_start   target\n",
      "126 2025-06-30  1308.74\n",
      "127 2025-07-07  1299.57\n",
      "128 2025-07-14  1318.98\n",
      "129 2025-07-21  1408.04\n",
      "130 2025-07-28  1609.03\n",
      "131 2025-08-04  1782.56\n",
      "132 2025-08-11  1741.72\n",
      "133 2025-08-18  1402.02\n",
      "134 2025-08-25  1101.07\n",
      "135 2025-09-01   969.84\n",
      "La semana objetivo 2025-09-15 NO está disponible para predicción.\n",
      "OK: Semana requerida para lag 1 presente: 2025-09-08\n",
      "OK: Semana requerida para lag 2 presente: 2025-09-01\n",
      "OK: Semana requerida para lag 52 presente: 2024-09-16\n",
      "Todas las semanas necesarias para los lags están presentes.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si la semana del 15/09/2025 y sus lags están presentes y son utilizables para predicción\n",
    "import pandas as pd\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "# Calcular la semana objetivo y los lags\n",
    "semana_objetivo = pd.Timestamp('2025-09-15')\n",
    "lags = [1, 2, 52]\n",
    "\n",
    "# Transformar el histórico a features y target\n",
    "features_and_target = transformar_features_target(\n",
    "    df_ts_historico,\n",
    "    lags_list=lags,\n",
    "    columna_target='base_imponible',\n",
    "    cols_exogenas=['is_summer_peak', 'is_easter'],\n",
    "    eliminar_nulos=True,\n",
    "    return_format='dataframe'\n",
    ")\n",
    "\n",
    "print(\"Semanas disponibles para predicción:\")\n",
    "print(features_and_target[['week_start', 'target']].tail(10))\n",
    "\n",
    "if semana_objetivo in features_and_target['week_start'].values:\n",
    "    print(f\"La semana objetivo {semana_objetivo.date()} está disponible para predicción.\")\n",
    "else:\n",
    "    print(f\"La semana objetivo {semana_objetivo.date()} NO está disponible para predicción.\")\n",
    "    # Comprobar si faltan semanas para los lags\n",
    "    ultima_semana = df_ts_historico['week_start'].max()\n",
    "    faltan_semanas = []\n",
    "    for lag in lags:\n",
    "        semana_requerida = semana_objetivo - pd.Timedelta(weeks=lag)\n",
    "        if semana_requerida not in df_ts_historico['week_start'].values:\n",
    "            faltan_semanas.append(semana_requerida)\n",
    "            print(f\"FALTA la semana requerida para lag {lag}: {semana_requerida.date()}\")\n",
    "        else:\n",
    "            print(f\"OK: Semana requerida para lag {lag} presente: {semana_requerida.date()}\")\n",
    "    if not faltan_semanas:\n",
    "        print(\"Todas las semanas necesarias para los lags están presentes.\")\n",
    "    else:\n",
    "        print(f\"Faltan las siguientes semanas para los lags: {[d.date() for d in faltan_semanas]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f7ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros encontrados en raw_all_data para la semana del 8 al 14/09/2025: 2483\n",
      "             fecha     n_factura zona_de_venta            producto  \\\n",
      "370724  2025-09-14  No facturado         SALON  7 CEREALS FORMATGE   \n",
      "370725  2025-09-14  No facturado         SALON  7 CEREALS FORMATGE   \n",
      "370726  2025-09-10  No facturado         SALON  7 CEREALS FORMATGE   \n",
      "370727  2025-09-12  No facturado       TERRAZA      7 CEREALS FUET   \n",
      "370728  2025-09-11  No facturado         BARRA      7 CEREALS FUET   \n",
      "\n",
      "           familia  cantidad  base_imponible  tipo_IVA  total  \n",
      "370724  BOCADILLOS       1.0            2.41      10.0   2.65  \n",
      "370725  BOCADILLOS       1.0            2.41      10.0   2.65  \n",
      "370726  BOCADILLOS       1.0            2.41      10.0   2.65  \n",
      "370727  BOCADILLOS       1.0            2.41      10.0   2.65  \n",
      "370728  BOCADILLOS       1.0            2.41      10.0   2.65  \n",
      "Registros en df_ts_historico para week_start=2025-09-08: 1\n",
      "     year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "136  2025    37  BOLLERIA          969.84               0          0   \n",
      "\n",
      "     dias_semana week_start  \n",
      "136            7 2025-09-08  \n"
     ]
    }
   ],
   "source": [
    "# Revisar si están los registros de la semana del 8 al 14 de septiembre de 2025 en el histórico\n",
    "import pandas as pd\n",
    "\n",
    "# Definir el rango de fechas de la semana\n",
    "fecha_inicio = pd.Timestamp('2025-09-08')\n",
    "fecha_fin = pd.Timestamp('2025-09-14')\n",
    "\n",
    "# Filtrar registros en el DataFrame original de ventas\n",
    "registros_semana = raw_all_data[(pd.to_datetime(raw_all_data['fecha']) >= fecha_inicio) & (pd.to_datetime(raw_all_data['fecha']) <= fecha_fin)]\n",
    "print(f\"Registros encontrados en raw_all_data para la semana del 8 al 14/09/2025: {len(registros_semana)}\")\n",
    "print(registros_semana.head())\n",
    "\n",
    "# Filtrar registros en el DataFrame de series temporales\n",
    "registros_ts_semana = df_ts_historico[df_ts_historico['week_start'] == fecha_inicio]\n",
    "print(f\"Registros en df_ts_historico para week_start={fecha_inicio.date()}: {len(registros_ts_semana)}\")\n",
    "print(registros_ts_semana)\n",
    "\n",
    "if len(registros_semana) == 0:\n",
    "    print(\"No hay registros de ventas en raw_all_data para esa semana. Revisa la descarga desde BigQuery.\")\n",
    "if len(registros_ts_semana) == 0:\n",
    "    print(\"No se generó la serie temporal para esa semana. Revisa la función de agregación semanal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f45925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semanas requeridas para lags:\n",
      "2025-09-08: Presente\n",
      "2025-09-01: Presente\n",
      "2025-08-25: Presente\n",
      "2024-09-16: Presente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Semanas requeridas para los lags de la predicción de la semana 15/09/2025\n",
    "semanas_lag = [\n",
    "    pd.to_datetime(\"2025-09-08\"),  # lag 1\n",
    "    pd.to_datetime(\"2025-09-01\"),  # lag 2\n",
    "    pd.to_datetime(\"2025-08-25\"),  # lag 3\n",
    "    pd.to_datetime(\"2024-09-16\"),  # lag 52\n",
    "]\n",
    "\n",
    "print(\"Semanas requeridas para lags:\")\n",
    "for semana in semanas_lag:\n",
    "    existe = semana in pd.to_datetime(df_ts_historico[\"week_start\"]).values\n",
    "    print(f\"{semana.date()}: {'Presente' if existe else 'Faltante'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
