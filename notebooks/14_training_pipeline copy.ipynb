{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94550aaf",
   "metadata": {},
   "source": [
    "# Pipeline de Entrenamiento con Feature Views de Hopsworks\n",
    "\n",
    "Este notebook implementa un pipeline completo para:\n",
    "1. Conectar al feature store de Hopsworks\n",
    "2. Crear una feature view con características seleccionadas\n",
    "3. Procesar los datos para crear variables de rezago (lags) y target\n",
    "4. Preparar los datos para entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502aeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añade el directorio raíz del proyecto al sys.path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e2364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46eabaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial\n",
    "from datetime import datetime\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configuración básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('feature_view_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46dd1251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 13:15:58,959 INFO: Initializing external client\n",
      "2025-09-06 13:15:58,960 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 13:16:00,161 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "2025-09-06 13:16:01,404 INFO: Conexión exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n"
     ]
    }
   ],
   "source": [
    "# 2. Conectar a Hopsworks y al Feature Store\n",
    "try:\n",
    "    # Login y conexión al proyecto\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=config.HOPSWORKS_API_KEY, \n",
    "        project=config.HOPSWORKS_PROJECT_NAME)\n",
    "    \n",
    "    # Conexión al feature store\n",
    "    feature_store = project.get_feature_store()\n",
    "    \n",
    "    # Conexión al feature group\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Conexión exitosa al Feature Group: {feature_group.name} (v{feature_group.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en conexión: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c98008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 13:16:10,225 INFO: Feature view existente recuperada: times_series_bolleria_feature_view (v1)\n"
     ]
    }
   ],
   "source": [
    "# 3. Crear/obtener feature view con características seleccionadas\n",
    "try:\n",
    "    # Características específicas a incluir\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    feature_view_name = config.FEATURE_VIEW_NAME\n",
    "    feature_view_version = 1\n",
    "    \n",
    "    # Intentar obtener la feature view existente primero\n",
    "    try:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version\n",
    "        )\n",
    "        logger.info(f\"Feature view existente recuperada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "    except:\n",
    "        # Si no existe, crear una nueva\n",
    "        # Obtener objetos Feature para las características seleccionadas\n",
    "        selected_feature_objects = [f for f in feature_group.features if f.name in selected_features]\n",
    "        \n",
    "        # Crear query con características seleccionadas\n",
    "        specific_query = feature_group.select(selected_feature_objects)\n",
    "        \n",
    "        # Crear la feature view\n",
    "        feature_view = feature_store.create_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version,\n",
    "            query=specific_query,\n",
    "            description=f\"Feature view con características: {', '.join(selected_features)}\"\n",
    "        )\n",
    "        logger.info(f\"Nueva feature view creada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al crear/obtener feature view: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7e897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.64s) \n",
      "2025-09-06 13:16:22,022 INFO: Datos obtenidos: 135 filas, 5 columnas\n",
      "2025-09-06 13:16:22,022 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "# 4. Obtener datos de la feature view\n",
    "try:\n",
    "    # Obtener datos en batch normal\n",
    "    df_ts = feature_view.get_batch_data()\n",
    "    \n",
    "    # Mostrar resumen de los datos obtenidos\n",
    "    logger.info(f\"Datos obtenidos: {df_ts.shape[0]} filas, {df_ts.shape[1]} columnas\")\n",
    "    logger.info(f\"Columnas disponibles: {list(df_ts.columns)}\")\n",
    "    print(\"Muestra de datos:\")\n",
    "    print(df_ts.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a1aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.60s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `49`.\n"
     ]
    }
   ],
   "source": [
    "# 5. Obtener datos de entrenamiento (training_data)\n",
    "try:\n",
    "    # Obtener datos de entrenamiento (X, y) desde la feature view\n",
    "    df_ts = feature_view.training_data()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al obtener datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1475b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 13:16:39,810 INFO: Detectada entrada tipo tupla con 2 elementos\n",
      "2025-09-06 13:16:39,810 INFO: Usando el primer elemento de la tupla como DataFrame: (135, 5)\n",
      "2025-09-06 13:16:39,816 INFO: Retornando DataFrame combinado: (82, 8)\n",
      "2025-09-06 13:16:39,816 INFO: Datos procesados: 82 filas, 8 columnas\n",
      "2025-09-06 13:16:39,817 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n"
     ]
    }
   ],
   "source": [
    "# 6. Procesar datos para entrenamiento\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "try:\n",
    "       \n",
    "    # Procesar datos usando la función mejorada que acepta tuplas directamente\n",
    "    features_and_target = transformar_features_target(\n",
    "        df_ts,\n",
    "        lags_list=[1, 2, 3, 52], \n",
    "        columna_target='base_imponible',\n",
    "        cols_exogenas=['is_easter', 'is_summer_peak'],\n",
    "        periodos_adelante=1,\n",
    "        eliminar_nulos=True,\n",
    "        return_format='dataframe'  # Obtenemos un único DataFrame con features y target\n",
    "    )\n",
    "    \n",
    "    # Mostrar información de los datos procesados\n",
    "    logger.info(f\"Datos procesados: {features_and_target.shape[0]} filas, {features_and_target.shape[1]} columnas\")\n",
    "    logger.info(f\"Variables disponibles: {list(features_and_target.columns)}\")\n",
    "    print(\"\\nMuestra de datos procesados:\")\n",
    "    print(features_and_target.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al procesar datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad845d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Split temporal y entrenamiento con XGBoost\n",
    "from src.data_split import train_test_split\n",
    "from src.model import train_evaluate_xgboost\n",
    "\n",
    "\n",
    "# Split temporal usando el 80% para train\n",
    "split_idx = int(len(features_and_target) * 0.8)\n",
    "split_date = features_and_target.loc[split_idx, 'week_start']\n",
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    features_and_target,\n",
    "    split_date=split_date,\n",
    "    target= 'target'  # o 'base_imponible' según tu pipeline\n",
    ")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca00ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Iniciando ajuste de hiperparámetros con GridSearchCV...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "✅ Ajuste de hiperparámetros finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento y evaluación\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Elimina la columna \"week_start\" si existe en X_train y X_test\n",
    "if 'week_start' in X_train.columns:\n",
    "    X_train = X_train.drop(columns=['week_start'])\n",
    "if 'week_start' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['week_start'])\n",
    "\n",
    "# Baseline con XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42)\n",
    "\n",
    "# Espacio de búsqueda para hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "# Timeseries split para validación cruzada\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_model,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")   \n",
    "\n",
    "print('⏳ Iniciando ajuste de hiperparámetros con GridSearchCV...')\n",
    "# Entrenamos el modelo\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('✅ Ajuste de hiperparámetros finalizado.')\n",
    "\n",
    "# Resultados del grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9de140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mejor puntuación (MAE negativo): 308.46038053385416\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "print(f\"Mejor puntuación (MAE negativo): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1c13c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE en test: 171.68, RMSE en test: 216.33, MAPE en test: 0.15, R2 en test: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Evaluación en test y guardado del mejor modelo\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import joblib\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE en test: {mae:.2f}, RMSE en test: {rmse:.2f}, MAPE en test: {mape:.2F}, R2 en test: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50726f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Workspace\\\\mlops_fleca_project\\\\models\\\\xgboost_hopsworks.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Guardar el modelo entrenado\n",
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "joblib.dump(best_model, MODELS_DIR / 'xgboost_hopsworks.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e6df2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "# cargamos el modelo\n",
    "model = joblib.load(MODELS_DIR / 'xgboost_hopsworks.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4456134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb62a5af058402d943c41e81eb362e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06e9c84846b460b9a9eb3fb75946825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading C:\\Workspace\\mlops_fleca_project\\models\\xgboost_hopsworks.pkl: 0.000%|          | 0/221241 elapsed<0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6224756f5fe48f0b0f8b3b18b0e7cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Workspace\\mlops_fleca_project\\notebooks\\input_example.json: 0.000%|          | 0/42 elapsed<00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5344d6506b4efe8db47dc1e751e42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Workspace\\mlops_fleca_project\\notebooks\\model_schema.json: 0.000%|          | 0/693 elapsed<00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1242272/models/fleca_bolleria_predictor_next_week/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'fleca_bolleria_predictor_next_week', version: 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Crear esquemas de entrada y salida para el modelo\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Eliminar columnas datetime no soportadas por XGBoost\n",
    "X_test_model = X_test.drop(columns=['week_start'], errors='ignore')\n",
    "\n",
    "# Realizar predicción con el modelo entrenado\n",
    "y_pred_xgb = best_model.predict(X_test_model)\n",
    "\n",
    "# Calcular MAE\n",
    "test_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Obtener el model registry de Hopsworks\n",
    "model_registry = project.get_model_registry()\n",
    "\n",
    "# Registrar el modelo en Hopsworks\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"fleca_bolleria_predictor_next_week\",\n",
    "    description=\"Modelo XGBoost para predecir la base imponible de bollería la próxima semana\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema,\n",
    "    metrics={\"mae\": test_mae}\n",
    "    )\n",
    "\n",
    "# Guardar el modelo localmente (convertir ruta a string para evitar AttributeError)\n",
    "model.save(str(MODELS_DIR / 'xgboost_hopsworks.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
