{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1397aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ENV HOPSWORKS_PROJECT_NAME: fleca_mlops\n",
      "DEBUG ENV PATH: C:\\Workspace\\mlops_fleca_project\\.env\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.data_utils import load_raw_data, transformar_a_series_temporales\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44557cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos históricos cargados: (356433, 9)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos directamente desde el archivo parquet en la carpeta raw\n",
    "parquet_path = r\"C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250803.parquet\"\n",
    "df_historico = pd.read_parquet(parquet_path)\n",
    "print('Datos históricos cargados:', df_historico.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d289f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series temporales históricas generadas: (131, 8)\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2023     1  BOLLERIA          825.11               0          0   \n",
      "1  2023     2  BOLLERIA          658.40               0          0   \n",
      "2  2023     3  BOLLERIA          741.40               0          0   \n",
      "3  2023     4  BOLLERIA          653.64               0          0   \n",
      "4  2023     5  BOLLERIA          680.46               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2023-01-02  \n",
      "1            7 2023-01-09  \n",
      "2            7 2023-01-16  \n",
      "3            7 2023-01-23  \n",
      "4            7 2023-01-30  \n"
     ]
    }
   ],
   "source": [
    "# Transformar a series temporales semanales para la familia BOLLERIA\n",
    "df_ts_historico = transformar_a_series_temporales(df_historico, familia=\"BOLLERIA\")\n",
    "print('Series temporales históricas generadas:', df_ts_historico.shape)\n",
    "print(df_ts_historico.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "750c6766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series temporales históricas generadas: (131, 8)\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2023     1  BOLLERIA          825.11               0          0   \n",
      "1  2023     2  BOLLERIA          658.40               0          0   \n",
      "2  2023     3  BOLLERIA          741.40               0          0   \n",
      "3  2023     4  BOLLERIA          653.64               0          0   \n",
      "4  2023     5  BOLLERIA          680.46               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2023-01-02  \n",
      "1            7 2023-01-09  \n",
      "2            7 2023-01-16  \n",
      "3            7 2023-01-23  \n",
      "4            7 2023-01-30  \n"
     ]
    }
   ],
   "source": [
    "df_ts_historico = transformar_a_series_temporales(df_historico, familia=\"BOLLERIA\")\n",
    "print('Series temporales históricas generadas:', df_ts_historico.shape)\n",
    "print(df_ts_historico.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cb3b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                       int64\n",
      "week                       int64\n",
      "familia           string[python]\n",
      "base_imponible           float64\n",
      "is_summer_peak             int32\n",
      "is_easter                  int64\n",
      "dias_semana                int64\n",
      "week_start        datetime64[ns]\n",
      "dtype: object\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2023     1  BOLLERIA          825.11               0          0   \n",
      "1  2023     2  BOLLERIA          658.40               0          0   \n",
      "2  2023     3  BOLLERIA          741.40               0          0   \n",
      "3  2023     4  BOLLERIA          653.64               0          0   \n",
      "4  2023     5  BOLLERIA          680.46               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2023-01-02  \n",
      "1            7 2023-01-09  \n",
      "2            7 2023-01-16  \n",
      "3            7 2023-01-23  \n",
      "4            7 2023-01-30  \n"
     ]
    }
   ],
   "source": [
    "# Eliminar columna 'fecha' si existe\n",
    "if 'fecha' in df_ts_historico.columns:\n",
    "    df_ts_historico = df_ts_historico.drop(columns=['fecha'])\n",
    "\n",
    "# Ajustar tipos para coincidir con el schema del Feature Group histórico\n",
    "df_ts_historico['year'] = df_ts_historico['year'].astype('int64')  # bigint\n",
    "df_ts_historico['week'] = df_ts_historico['week'].astype('int64')  # bigint\n",
    "df_ts_historico['familia'] = df_ts_historico['familia'].astype('string')  # string\n",
    "df_ts_historico['base_imponible'] = df_ts_historico['base_imponible'].astype('float64')  # double\n",
    "df_ts_historico['is_summer_peak'] = df_ts_historico['is_summer_peak'].astype('int32')  # int\n",
    "df_ts_historico['is_easter'] = df_ts_historico['is_easter'].astype('int64')  # bigint\n",
    "df_ts_historico['week_start'] = pd.to_datetime(df_ts_historico['week_start'])  # timestamp\n",
    "\n",
    "print(df_ts_historico.dtypes)\n",
    "print(df_ts_historico.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb2e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 13:21:01,748 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-08-15 13:21:01,751 INFO: Initializing external client\n",
      "2025-08-15 13:21:01,752 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-08-15 13:21:01,751 INFO: Initializing external client\n",
      "2025-08-15 13:21:01,752 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 13:21:02,843 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n"
     ]
    }
   ],
   "source": [
    "# 5. Conectar a hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=config.HOPSWORKS_API_KEY, \n",
    "    project=config.HOPSWORKS_PROJECT_NAME)\n",
    "\n",
    " # Conectar al feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    " # Conectar al Feature Group histórico\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    primary_key=[\"familia\", \"week_start\"],\n",
    "    event_time=\"week_start\"\n",
    ")\n",
    "\n",
    "if feature_group is None:\n",
    "    raise Exception(\"El Feature Group histórico no existe o el nombre/version no coinciden exactamente. Verifica en Hopsworks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aff050a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 131/131 | Elapsed Time: 00:00 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: times_series_bolleria_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/times_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/times_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "2025-08-15 13:21:53,474 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-08-15 13:21:53,474 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-08-15 13:21:56,632 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-08-15 13:21:56,632 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-08-15 13:23:22,101 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-08-15 13:23:22,101 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-08-15 13:23:22,245 INFO: Waiting for log aggregation to finish.\n",
      "2025-08-15 13:23:22,245 INFO: Waiting for log aggregation to finish.\n",
      "2025-08-15 13:23:34,125 INFO: Execution finished successfully.\n",
      "2025-08-15 13:23:34,125 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('times_series_bolleria_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insertar los datos en el Feature Group\n",
    "feature_group.insert(\n",
    "    df_ts_historico,\n",
    "    write_options={'wait_for_job': True}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
