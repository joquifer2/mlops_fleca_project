{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a5c4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añade src al path para importar los módulos\n",
    "sys.path.append(str(Path().resolve().parent / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e412d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc80d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('feature_view_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddad7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 12:04:58,827 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-08-23 12:04:58,831 INFO: Initializing external client\n",
      "2025-08-23 12:04:58,831 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-08-23 12:04:58,831 INFO: Initializing external client\n",
      "2025-08-23 12:04:58,831 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 12:04:59,984 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "2025-08-23 12:05:01,258 INFO: Conexión exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n",
      "2025-08-23 12:05:01,258 INFO: Conexión exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n"
     ]
    }
   ],
   "source": [
    "# Conectar a Hopsworks y al Feature Store\n",
    "try:\n",
    "    # Login y conexión al proyecto\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=config.HOPSWORKS_API_KEY, \n",
    "        project=config.HOPSWORKS_PROJECT_NAME)\n",
    "    \n",
    "    # Conexión al feature store\n",
    "    feature_store = project.get_feature_store()\n",
    "    \n",
    "    # Conexión al feature group\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Conexión exitosa al Feature Group: {feature_group.name} (v{feature_group.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en conexión: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc46d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 12:05:02,520 INFO: Feature view existente recuperada: times_series_bolleria_feature_view (v1)\n"
     ]
    }
   ],
   "source": [
    "# Crear/obtener feature view con características seleccionadas\n",
    "try:\n",
    "    # Características específicas a incluir\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    feature_view_name = config.FEATURE_VIEW_NAME\n",
    "    feature_view_version = 1\n",
    "    \n",
    "    # Intentar obtener la feature view existente primero\n",
    "    try:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version\n",
    "        )\n",
    "        logger.info(f\"Feature view existente recuperada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "    except:\n",
    "        # Si no existe, crear una nueva\n",
    "        # Obtener objetos Feature para las características seleccionadas\n",
    "        selected_feature_objects = [f for f in feature_group.features if f.name in selected_features]\n",
    "        \n",
    "        # Crear query con características seleccionadas\n",
    "        specific_query = feature_group.select(selected_feature_objects)\n",
    "        \n",
    "        # Crear la feature view\n",
    "        feature_view = feature_store.create_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version,\n",
    "            query=specific_query,\n",
    "            description=f\"Feature view con características: {', '.join(selected_features)}\"\n",
    "        )\n",
    "        logger.info(f\"Nueva feature view creada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al crear/obtener feature view: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0eb477b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.65s) \n",
      "2025-08-23 12:05:06,321 INFO: Datos obtenidos: 133 filas, 5 columnas\n",
      "2025-08-23 12:05:06,322 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.65s) \n",
      "2025-08-23 12:05:06,321 INFO: Datos obtenidos: 133 filas, 5 columnas\n",
      "2025-08-23 12:05:06,322 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Obtener datos de la feature view\n",
    "try:\n",
    "    # Obtener datos en batch normal\n",
    "    df_ts = feature_view.get_batch_data()\n",
    "    \n",
    "    # Mostrar resumen de los datos obtenidos\n",
    "    logger.info(f\"Datos obtenidos: {df_ts.shape[0]} filas, {df_ts.shape[1]} columnas\")\n",
    "    logger.info(f\"Columnas disponibles: {list(df_ts.columns)}\")\n",
    "    print(\"Muestra de datos:\")\n",
    "    print(df_ts.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0f1a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.64s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.64s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `7`.\n"
     ]
    }
   ],
   "source": [
    "# Obtener datos de entrenamiento (training_data)\n",
    "try:\n",
    "    # Obtener datos de entrenamiento (X, y) desde la feature view\n",
    "    df_ts = feature_view.training_data()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al obtener datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09821c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-23 12:05:10,561 INFO: Detectada entrada tipo tupla con 2 elementos\n",
      "2025-08-23 12:05:10,561 INFO: Usando el primer elemento de la tupla como DataFrame: (133, 5)\n",
      "2025-08-23 12:05:10,564 INFO: Retornando DataFrame combinado: (80, 8)\n",
      "2025-08-23 12:05:10,566 INFO: Datos procesados: 80 filas, 8 columnas\n",
      "2025-08-23 12:05:10,566 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n",
      "2025-08-23 12:05:10,561 INFO: Usando el primer elemento de la tupla como DataFrame: (133, 5)\n",
      "2025-08-23 12:05:10,564 INFO: Retornando DataFrame combinado: (80, 8)\n",
      "2025-08-23 12:05:10,566 INFO: Datos procesados: 80 filas, 8 columnas\n",
      "2025-08-23 12:05:10,566 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n"
     ]
    }
   ],
   "source": [
    "# Procesar datos para entrenamiento\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "try:\n",
    "       \n",
    "    # Procesar datos usando la función mejorada que acepta tuplas directamente\n",
    "    features_and_target = transformar_features_target(\n",
    "        df_ts,\n",
    "        lags_list=[1, 2, 3, 52], \n",
    "        columna_target='base_imponible',\n",
    "        cols_exogenas=['is_easter', 'is_summer_peak'],\n",
    "        periodos_adelante=1,\n",
    "        eliminar_nulos=True,\n",
    "        return_format='dataframe'  # Obtenemos un único DataFrame con features y target\n",
    "    )\n",
    "    \n",
    "    # Mostrar información de los datos procesados\n",
    "    logger.info(f\"Datos procesados: {features_and_target.shape[0]} filas, {features_and_target.shape[1]} columnas\")\n",
    "    logger.info(f\"Variables disponibles: {list(features_and_target.columns)}\")\n",
    "    print(\"\\nMuestra de datos procesados:\")\n",
    "    print(features_and_target.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al procesar datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6418c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (65, 7), Test: (15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Split temporal (automático 80/20 ya incluido en la función)\n",
    "from src.data_split import train_test_split\n",
    "\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = train_test_split(\n",
    "        features_and_target,\n",
    "        target='target'  # o 'base_imponible' según tu pipeline\n",
    "        # split_ratio=0.8  # puedes cambiar el porcentaje si lo necesitas\n",
    "    )\n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en el split temporal: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d181a2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Workspace/mlops_fleca_project/mlruns/1', creation_time=1755943087557, experiment_id='1', last_update_time=1755943087557, lifecycle_stage='active', name='fleca_bolleria_xgboost', tags={}>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración de MLflow\n",
    "mlflow.set_tracking_uri(config.MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"fleca_bolleria_xgboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54263c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas datetime antes de entrenar\n",
    "for df in [X_train, X_test]:\n",
    "    if 'week_start' in df.columns:\n",
    "        df.drop('week_start', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "032d4bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 12:37:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "UserWarning: [12:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "UserWarning: [12:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "2025/08/23 12:37:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/23 12:37:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 194.05842610677084\n",
      "MSE: 54390.89484225258\n",
      "R2: 0.4041277259384527\n",
      "🏃 View run xgboost at: http://localhost:5000/#/experiments/1/runs/a40a756cc688464c835fd36d9fe98b9b\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Importar XGBoost y métricas\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Definimos los modelos a entrenar\n",
    "with mlflow.start_run(run_name=\"xgboost\"):\n",
    "    # Entrenamos el modelo\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos predicciones\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Log de los parámetros\n",
    "    mlflow.log_param(\"model\", \"xgboost\")\n",
    "    for param, value in model.get_params().items():\n",
    "        mlflow.log_param(param, value)\n",
    "\n",
    "    # Log de las métricas\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log del modelo\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad61e19",
   "metadata": {},
   "source": [
    "# ESte no funciona (hay que investigar por qué)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ebe5d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 12:24:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "UserWarning: [12:24:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "UserWarning: [12:24:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "2025/08/23 12:24:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/23 12:24:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 236.2600927734375\n",
      "R2: 0.08752420359999014\n",
      "🏃 View run xgboost at: http://localhost:5000/#/experiments/1/runs/65ddfe3dd1954b21a34ab0388987d4e4\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento y evaluación con XGBoost\n",
    "from src.model import train_evaluate_xgboost\n",
    "\n",
    "# Eliminar columnas datetime antes de entrenar\n",
    "for df in [X_train, X_test]:\n",
    "    if 'week_start' in df.columns:\n",
    "        df.drop('week_start', axis=1, inplace=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost\"):\n",
    "    resultados = train_evaluate_xgboost(X_train, y_train, X_test, y_test)\n",
    "    model = resultados[\"model\"]\n",
    "\n",
    "    # Log de los parámetros del modelo\n",
    "    mlflow.log_param(\"model\", \"xgboost\")\n",
    "    for param, value in model.get_params().items():\n",
    "        mlflow.log_param(param, value)\n",
    "\n",
    "    # Log de las métricas\n",
    "    mlflow.log_metric(\"mae\", resultados[\"mae\"])\n",
    "    \n",
    "    mlflow.log_metric(\"r2\", resultados[\"r2\"])\n",
    "\n",
    "    # Log del modelo\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"MAE: {resultados['mae']}\")\n",
    "   \n",
    "    print(f\"R2: {resultados['r2']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
