{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46eabaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports - Librerías necesarias\n",
    "from datetime import datetime\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configuración básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('feature_view_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46dd1251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 19:43:09,828 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-08-15 19:43:09,832 INFO: Initializing external client\n",
      "2025-08-15 19:43:09,832 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-08-15 19:43:09,832 INFO: Initializing external client\n",
      "2025-08-15 19:43:09,832 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-08-15 19:43:11,118 INFO: Python Engine initialized.\n",
      "2025-08-15 19:43:11,118 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "2025-08-15 19:43:12,783 INFO: Conectado a Feature Group: times_series_bolleria_feature_group (v1)\n",
      "2025-08-15 19:43:12,783 INFO: Conectado a Feature Group: times_series_bolleria_feature_group (v1)\n"
     ]
    }
   ],
   "source": [
    "# 2. Conectar a Hopsworks y al Feature Group\n",
    "try:\n",
    "    # Login y conexión al proyecto\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=config.HOPSWORKS_API_KEY, \n",
    "        project=config.HOPSWORKS_PROJECT_NAME)\n",
    "    \n",
    "    # Conexión al feature store\n",
    "    feature_store = project.get_feature_store()\n",
    "    \n",
    "    # Conexión al feature group\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Conectado a Feature Group: {feature_group.name} (v{feature_group.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en conexión: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d9e3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 19:43:12,802 INFO: Características en times_series_bolleria_feature_group:\n",
      "2025-08-15 19:43:12,802 INFO:   - year (bigint)\n",
      "2025-08-15 19:43:12,803 INFO:   - week (bigint)\n",
      "2025-08-15 19:43:12,803 INFO:   - familia (string)\n",
      "2025-08-15 19:43:12,804 INFO:   - base_imponible (double)\n",
      "2025-08-15 19:43:12,806 INFO:   - is_summer_peak (int)\n",
      "2025-08-15 19:43:12,806 INFO:   - is_easter (bigint)\n",
      "2025-08-15 19:43:12,806 INFO:   - dias_semana (bigint)\n",
      "2025-08-15 19:43:12,806 INFO:   - week_start (timestamp)\n",
      "2025-08-15 19:43:12,807 INFO: Primary keys: ['familia', 'week_start']\n",
      "2025-08-15 19:43:12,807 INFO: Event time: week_start\n",
      "2025-08-15 19:43:12,802 INFO:   - year (bigint)\n",
      "2025-08-15 19:43:12,803 INFO:   - week (bigint)\n",
      "2025-08-15 19:43:12,803 INFO:   - familia (string)\n",
      "2025-08-15 19:43:12,804 INFO:   - base_imponible (double)\n",
      "2025-08-15 19:43:12,806 INFO:   - is_summer_peak (int)\n",
      "2025-08-15 19:43:12,806 INFO:   - is_easter (bigint)\n",
      "2025-08-15 19:43:12,806 INFO:   - dias_semana (bigint)\n",
      "2025-08-15 19:43:12,806 INFO:   - week_start (timestamp)\n",
      "2025-08-15 19:43:12,807 INFO: Primary keys: ['familia', 'week_start']\n",
      "2025-08-15 19:43:12,807 INFO: Event time: week_start\n"
     ]
    }
   ],
   "source": [
    "# 3. Verificar características disponibles\n",
    "try:\n",
    "    # Obtener lista de características\n",
    "    features = feature_group.features\n",
    "    \n",
    "    # Mostrar nombres y tipos\n",
    "    logger.info(f\"Características en {feature_group.name}:\")\n",
    "    for feature in features:\n",
    "        logger.info(f\"  - {feature.name} ({feature.type})\")\n",
    "        \n",
    "    # Mostrar primary keys y event time\n",
    "    logger.info(f\"Primary keys: {feature_group.primary_key}\")\n",
    "    logger.info(f\"Event time: {feature_group.event_time}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener características: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78c1eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 19:43:12,818 INFO: Limpieza de feature views completada\n"
     ]
    }
   ],
   "source": [
    "# 4. Borrar feature views existentes\n",
    "try:\n",
    "    # Intentar borrar versiones específicas que podrían existir\n",
    "    versions_to_delete = [1, 2]\n",
    "    \n",
    "    for version in versions_to_delete:\n",
    "        try:\n",
    "            feature_store.delete_feature_view(name=config.FEATURE_VIEW_NAME, version=version)\n",
    "            logger.info(f\"Feature view '{config.FEATURE_VIEW_NAME}' (v{version}) eliminada\")\n",
    "        except Exception:\n",
    "            pass  # Ignorar errores si la feature view no existe\n",
    "            \n",
    "    logger.info(\"Limpieza de feature views completada\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al borrar feature views: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "573aea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 19:43:13,708 ERROR: Error al crear feature view: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1242272/featurestores/1224799/featureview). Server response: \n",
      "HTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270179,\"usrMsg\":\"Feature view: times_series_bolleria_feature_view, version: 1\",\"errorMsg\":\"The provided feature view name and version already exists\"}', error code: 270179, error msg: The provided feature view name and version already exists, user msg: Feature view: times_series_bolleria_feature_view, version: 1\n"
     ]
    }
   ],
   "source": [
    "# 5. Crear feature view con características seleccionadas\n",
    "try:\n",
    "    # Características específicas a incluir\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    \n",
    "    # Verificar existencia de las características\n",
    "    available_features = [f.name for f in feature_group.features]\n",
    "    missing_features = [f for f in selected_features if f not in available_features]\n",
    "    \n",
    "    if missing_features:\n",
    "        logger.warning(f\"Características no encontradas: {missing_features}\")\n",
    "        # Buscar posibles coincidencias por nombre\n",
    "        selected_features = [f for f in selected_features if f in available_features]\n",
    "    \n",
    "    # Configurar feature view\n",
    "    feature_view_name = config.FEATURE_VIEW_NAME\n",
    "    feature_view_version = 1\n",
    "    \n",
    "    # Obtener objetos Feature para las características seleccionadas\n",
    "    selected_feature_objects = [f for f in feature_group.features if f.name in selected_features]\n",
    "    \n",
    "    # Crear query con características seleccionadas\n",
    "    specific_query = feature_group.select(selected_feature_objects)\n",
    "    \n",
    "    # Crear la feature view\n",
    "    feature_view = feature_store.create_feature_view(\n",
    "        name=feature_view_name,\n",
    "        version=feature_view_version,\n",
    "        query=specific_query,\n",
    "        description=f\"Feature view con características: {', '.join(selected_features)}\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Feature view creada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al crear feature view: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c98008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.53s) \n",
      "2025-08-15 19:43:17,652 INFO: Columnas en datos: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "2025-08-15 19:43:17,653 INFO: Dimensiones: (132, 5)\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "3  BOLLERIA          785.98               0          0   \n",
      "4  BOLLERIA          915.18               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n",
      "3 2023-02-27 00:00:00+00:00  \n",
      "4 2024-04-29 00:00:00+00:00  \n",
      "2025-08-15 19:43:17,654 INFO: Todas las características solicitadas están presentes\n",
      "2025-08-15 19:43:17,657 INFO: Datos guardados en data/processed/feature_view_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# 6. Acceder a los datos de la feature view\n",
    "try:\n",
    "    # Obtener la feature view por nombre si no está disponible\n",
    "    if 'feature_view' not in locals() or feature_view is None:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=config.FEATURE_VIEW_NAME,\n",
    "            version=1\n",
    "        )\n",
    "    \n",
    "    # Obtener los datos\n",
    "    data = feature_view.get_batch_data()\n",
    "    \n",
    "    # Verificar columnas obtenidas\n",
    "    logger.info(f\"Columnas en datos: {list(data.columns)}\")\n",
    "    logger.info(f\"Dimensiones: {data.shape}\")\n",
    "    \n",
    "    # Mostrar primeros registros\n",
    "    print(data.head())\n",
    "    \n",
    "    # Verificar presencia de características solicitadas\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    missing_cols = [col for col in selected_features if col not in data.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        logger.warning(f\"Columnas faltantes: {missing_cols}\")\n",
    "    else:\n",
    "        logger.info(\"Todas las características solicitadas están presentes\")\n",
    "    \n",
    "    # Guardar datos para uso posterior\n",
    "    data_path = \"data/processed/feature_view_data.parquet\"\n",
    "    data.to_parquet(data_path, index=False)\n",
    "    logger.info(f\"Datos guardados en {data_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al acceder a datos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86a1aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.92s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.92s) \n",
      "2025-08-15 19:43:37,715 INFO: Provenance cached data - overwriting last accessed/created training dataset from 3 to 4.\n",
      "2025-08-15 19:43:37,716 INFO: Tipo de datos retornado por training_data(): <class 'tuple'>\n",
      "2025-08-15 19:43:37,717 ERROR: Error al obtener datos de entrenamiento: 'NoneType' object has no attribute 'shape'\n",
      "2025-08-15 19:43:37,715 INFO: Provenance cached data - overwriting last accessed/created training dataset from 3 to 4.\n",
      "2025-08-15 19:43:37,716 INFO: Tipo de datos retornado por training_data(): <class 'tuple'>\n",
      "2025-08-15 19:43:37,717 ERROR: Error al obtener datos de entrenamiento: 'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `4`.\n"
     ]
    }
   ],
   "source": [
    "# 6b. Obtener datos de entrenamiento con training_data()\n",
    "try:\n",
    "    # Obtener datos de entrenamiento (devuelve una tupla con X e y)\n",
    "    df_ts = feature_view.training_data()\n",
    "    \n",
    "    # Verificar el tipo de retorno\n",
    "    logger.info(f\"Tipo de datos retornado por training_data(): {type(df_ts)}\")\n",
    "    \n",
    "    # Si es una tupla, extraer los componentes\n",
    "    if isinstance(df_ts, tuple):\n",
    "        X_train, y_train = df_ts\n",
    "        logger.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        \n",
    "        # Crear un DataFrame combinado para visualización\n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_col_name = y_train.name if y_train.name else 'target'\n",
    "            df_combined = X_train.copy()\n",
    "            df_combined[y_col_name] = y_train\n",
    "        else:\n",
    "            # Si y_train es un array o DataFrame\n",
    "            df_combined = pd.concat([X_train, \n",
    "                                    pd.DataFrame(y_train, columns=['target'])], axis=1)\n",
    "            \n",
    "        print(\"Primeras filas del conjunto de datos de entrenamiento:\")\n",
    "        print(df_combined.head())\n",
    "    else:\n",
    "        # Si no es una tupla, asumir que es un DataFrame directamente\n",
    "        print(\"Primeras filas del conjunto de datos de entrenamiento:\")\n",
    "        print(df_ts.head())\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "726f36c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Características (X) ===\n",
      "Forma: (132, 5)\n",
      "Columnas: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Primeras 5 filas:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "3  BOLLERIA          785.98               0          0   \n",
      "4  BOLLERIA          915.18               0          0   \n",
      "\n",
      "                  week_start  \n",
      "0  2023-02-06 00:00:00+00:00  \n",
      "1  2025-02-24 00:00:00+00:00  \n",
      "2  2023-09-18 00:00:00+00:00  \n",
      "3  2023-02-27 00:00:00+00:00  \n",
      "4  2024-04-29 00:00:00+00:00  \n",
      "\n",
      "=== Variable objetivo (y) ===\n",
      "Tipo: <class 'NoneType'>\n",
      "Forma: No disponible\n",
      "Primeros 5 valores:\n",
      "No se pueden mostrar los valores\n"
     ]
    }
   ],
   "source": [
    "# 6c. Explorar los componentes de los datos de entrenamiento\n",
    "try:\n",
    "    # Verificar que df_ts esté definido\n",
    "    if 'df_ts' not in locals():\n",
    "        logger.warning(\"Variable df_ts no encontrada. Ejecute primero la celda anterior.\")\n",
    "    # Si df_ts es una tupla, mostrar información detallada de sus componentes\n",
    "    elif isinstance(df_ts, tuple) and len(df_ts) >= 2:\n",
    "        # Desempaquetar la tupla\n",
    "        X_features, y_target = df_ts\n",
    "        \n",
    "        print(\"=== Características (X) ===\")\n",
    "        print(f\"Forma: {X_features.shape}\")\n",
    "        print(f\"Columnas: {list(X_features.columns)}\")\n",
    "        print(\"Primeras 5 filas:\")\n",
    "        print(X_features.head())\n",
    "        \n",
    "        print(\"\\n=== Variable objetivo (y) ===\")\n",
    "        if isinstance(y_target, pd.Series):\n",
    "            print(f\"Nombre: {y_target.name}\")\n",
    "            print(f\"Forma: {y_target.shape}\")\n",
    "            print(\"Primeros 5 valores:\")\n",
    "            print(y_target.head())\n",
    "        else:\n",
    "            print(f\"Tipo: {type(y_target)}\")\n",
    "            print(f\"Forma: {y_target.shape if hasattr(y_target, 'shape') else 'No disponible'}\")\n",
    "            try:\n",
    "                print(\"Primeros 5 valores:\")\n",
    "                print(y_target[:5])\n",
    "            except:\n",
    "                print(\"No se pueden mostrar los valores\")\n",
    "    else:\n",
    "        # Si df_ts no es una tupla\n",
    "        print(f\"Los datos no están en formato tupla (X, y). Tipo actual: {type(df_ts)}\")\n",
    "        try:\n",
    "            if hasattr(df_ts, 'head'):\n",
    "                print(df_ts.head())\n",
    "            else:\n",
    "                print(f\"No se puede mostrar vista previa para tipo {type(df_ts)}\")\n",
    "        except Exception as inner_e:\n",
    "            print(f\"Error al mostrar datos: {inner_e}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al explorar datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1475b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 19:53:58,660 INFO: Extrayendo DataFrame de características de df_ts: (132, 5)\n",
      "2025-08-15 19:53:58,663 INFO: La función transformar_features_target devolvió 3 valores\n",
      "2025-08-15 19:53:58,664 INFO: Se ignoraron 1 valores adicionales devueltos\n",
      "DataFrame procesado: features_and_target.shape=(127, 6)\n",
      "Columnas disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag4', 'week_start', 'target']\n",
      "    base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "99               653.64               741.40               658.40   \n",
      "0                680.46               653.64               741.40   \n",
      "70               641.56               680.46               653.64   \n",
      "89               649.83               641.56               680.46   \n",
      "3                713.33               649.83               641.56   \n",
      "\n",
      "    base_imponible_lag4                 week_start  target  \n",
      "99               825.11  2023-01-30 00:00:00+00:00  641.56  \n",
      "0                658.40  2023-02-06 00:00:00+00:00  649.83  \n",
      "70               741.40  2023-02-13 00:00:00+00:00  713.33  \n",
      "89               653.64  2023-02-20 00:00:00+00:00  785.98  \n",
      "3                680.46  2023-02-27 00:00:00+00:00  697.63  \n",
      "2025-08-15 19:53:58,663 INFO: La función transformar_features_target devolvió 3 valores\n",
      "2025-08-15 19:53:58,664 INFO: Se ignoraron 1 valores adicionales devueltos\n",
      "DataFrame procesado: features_and_target.shape=(127, 6)\n",
      "Columnas disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag4', 'week_start', 'target']\n",
      "    base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "99               653.64               741.40               658.40   \n",
      "0                680.46               653.64               741.40   \n",
      "70               641.56               680.46               653.64   \n",
      "89               649.83               641.56               680.46   \n",
      "3                713.33               649.83               641.56   \n",
      "\n",
      "    base_imponible_lag4                 week_start  target  \n",
      "99               825.11  2023-01-30 00:00:00+00:00  641.56  \n",
      "0                658.40  2023-02-06 00:00:00+00:00  649.83  \n",
      "70               741.40  2023-02-13 00:00:00+00:00  713.33  \n",
      "89               653.64  2023-02-20 00:00:00+00:00  785.98  \n",
      "3                680.46  2023-02-27 00:00:00+00:00  697.63  \n"
     ]
    }
   ],
   "source": [
    "# 6d. Procesar datos para entrenamiento\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "# Extraer el DataFrame de características de la tupla df_ts\n",
    "if isinstance(df_ts, tuple) and len(df_ts) >= 1:\n",
    "    # Extraer solo el primer componente (DataFrame de características)\n",
    "    df_features = df_ts[0]\n",
    "    logger.info(f\"Extrayendo DataFrame de características de df_ts: {df_features.shape}\")\n",
    "else:\n",
    "    logger.error(\"df_ts no tiene el formato esperado (tupla)\")\n",
    "    raise TypeError(\"df_ts debe ser una tupla que contenga al menos un DataFrame\")\n",
    "\n",
    "# Ahora procesamos el DataFrame de características\n",
    "# Capturar todos los valores retornados en una variable\n",
    "result = transformar_features_target(\n",
    "    df_features,\n",
    "    lags_list=[1, 2, 3, 4], \n",
    "    columna_target='base_imponible',\n",
    "    cols_exogenas=None,\n",
    "    periodos_adelante=1,\n",
    "    eliminar_nulos=True\n",
    ")\n",
    "\n",
    "# Verificar cuántos valores devuelve la función\n",
    "logger.info(f\"La función transformar_features_target devolvió {len(result) if isinstance(result, tuple) else 1} valores\")\n",
    "\n",
    "# Extraer los valores según la cantidad devuelta\n",
    "if isinstance(result, tuple):\n",
    "    if len(result) == 2:\n",
    "        features, target = result\n",
    "    elif len(result) >= 3:\n",
    "        features, target = result[0], result[1]\n",
    "        logger.info(f\"Se ignoraron {len(result) - 2} valores adicionales devueltos\")\n",
    "    else:\n",
    "        features = result[0]\n",
    "        target = None\n",
    "        logger.warning(\"No se obtuvo un valor para 'target'\")\n",
    "else:\n",
    "    # Si solo devuelve un valor\n",
    "    features = result\n",
    "    target = None\n",
    "    logger.warning(\"La función solo devolvió un valor (features)\")\n",
    "\n",
    "# Combinar características y objetivo en un solo DataFrame si ambos existen\n",
    "if features is not None and target is not None:\n",
    "    features_and_target = features.copy()\n",
    "    features_and_target['target'] = target\n",
    "    \n",
    "    print(f'DataFrame procesado: {features_and_target.shape=}')\n",
    "    print(f'Columnas disponibles: {list(features_and_target.columns)}')\n",
    "    print(features_and_target.head())\n",
    "elif features is not None:\n",
    "    print(f'Solo se obtuvieron características: {features.shape=}')\n",
    "    print(f'Columnas disponibles: {list(features.columns)}')\n",
    "    print(features.head())\n",
    "else:\n",
    "    logger.error(\"No se obtuvieron características válidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7903318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Entrenar modelo básico con las características seleccionadas\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import numpy as np\n",
    "    \n",
    "    # Definir características y objetivo (ajustar según datos)\n",
    "    X = data[['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']]\n",
    "    y = data['ventas'] if 'ventas' in data.columns else data.iloc[:, -1]  # Última columna como fallback\n",
    "    \n",
    "    # División train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Resultados\n",
    "    logger.info(f\"Resultados del modelo RandomForest:\")\n",
    "    logger.info(f\"RMSE: {rmse:.4f}\")\n",
    "    logger.info(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    # Importancia de características\n",
    "    importances = pd.DataFrame({\n",
    "        'Característica': X.columns,\n",
    "        'Importancia': model.feature_importances_\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    print(\"Importancia de características:\")\n",
    "    print(importances)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en entrenamiento: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
