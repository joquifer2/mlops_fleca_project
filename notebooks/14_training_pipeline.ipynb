{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96199b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añade el directorio raíz del proyecto al sys.path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cbb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492cf5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ENV HOPSWORKS_PROJECT_NAME: fleca_mlops\n",
      "DEBUG ENV PATH: C:\\Workspace\\mlops_fleca_project\\.env\n"
     ]
    }
   ],
   "source": [
    "# Importar desde src como paquete\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ec7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial\n",
    "from datetime import datetime\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configuración básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('feature_view_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46dd1251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 18:53:13,001 INFO: Initializing external client\n",
      "2025-09-06 18:53:13,001 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-09-06 18:53:13,001 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 18:53:14,437 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "2025-09-06 18:53:15,781 INFO: Conexión exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n",
      "2025-09-06 18:53:15,781 INFO: Conexión exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n"
     ]
    }
   ],
   "source": [
    "# 2. Conectar a Hopsworks y al Feature Store\n",
    "try:\n",
    "    # Login y conexión al proyecto\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=config.HOPSWORKS_API_KEY, \n",
    "        project=config.HOPSWORKS_PROJECT_NAME)\n",
    "    \n",
    "    # Conexión al feature store\n",
    "    feature_store = project.get_feature_store()\n",
    "    \n",
    "    # Conexión al feature group\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Conexión exitosa al Feature Group: {feature_group.name} (v{feature_group.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en conexión: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c98008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 18:54:08,870 INFO: Feature view existente recuperada: times_series_bolleria_feature_view (v1)\n"
     ]
    }
   ],
   "source": [
    "# 3. Crear/obtener feature view con características seleccionadas\n",
    "try:\n",
    "    # Características específicas a incluir\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    feature_view_name = config.FEATURE_VIEW_NAME\n",
    "    feature_view_version = 1\n",
    "    \n",
    "    # Intentar obtener la feature view existente primero\n",
    "    try:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version\n",
    "        )\n",
    "        logger.info(f\"Feature view existente recuperada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "    except:\n",
    "        # Si no existe, crear una nueva\n",
    "        # Obtener objetos Feature para las características seleccionadas\n",
    "        selected_feature_objects = [f for f in feature_group.features if f.name in selected_features]\n",
    "        \n",
    "        # Crear query con características seleccionadas\n",
    "        specific_query = feature_group.select(selected_feature_objects)\n",
    "        \n",
    "        # Crear la feature view\n",
    "        feature_view = feature_store.create_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version,\n",
    "            query=specific_query,\n",
    "            description=f\"Feature view con características: {', '.join(selected_features)}\"\n",
    "        )\n",
    "        logger.info(f\"Nueva feature view creada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al crear/obtener feature view: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7e897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "2025-09-06 18:54:20,622 INFO: Datos obtenidos: 135 filas, 5 columnas\n",
      "2025-09-06 18:54:20,622 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "2025-09-06 18:54:20,622 INFO: Datos obtenidos: 135 filas, 5 columnas\n",
      "2025-09-06 18:54:20,622 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "# 4. Obtener datos de la feature view\n",
    "try:\n",
    "    # Obtener datos en batch normal\n",
    "    df_ts = feature_view.get_batch_data()\n",
    "    \n",
    "    # Mostrar resumen de los datos obtenidos\n",
    "    logger.info(f\"Datos obtenidos: {df_ts.shape[0]} filas, {df_ts.shape[1]} columnas\")\n",
    "    logger.info(f\"Columnas disponibles: {list(df_ts.columns)}\")\n",
    "    print(\"Muestra de datos:\")\n",
    "    print(df_ts.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a1aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.59s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.59s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `51`.\n"
     ]
    }
   ],
   "source": [
    "# 5. Obtener datos de entrenamiento (training_data)\n",
    "try:\n",
    "    # Obtener datos de entrenamiento (X, y) desde la feature view\n",
    "    df_ts = feature_view.training_data()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al obtener datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1475b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 18:54:38,948 INFO: Detectada entrada tipo tupla con 2 elementos\n",
      "2025-09-06 18:54:38,949 INFO: Usando el primer elemento de la tupla como DataFrame: (135, 5)\n",
      "2025-09-06 18:54:38,955 INFO: Retornando DataFrame combinado: (82, 8)\n",
      "2025-09-06 18:54:38,956 INFO: Datos procesados: 82 filas, 8 columnas\n",
      "2025-09-06 18:54:38,956 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "2025-09-06 18:54:38,949 INFO: Usando el primer elemento de la tupla como DataFrame: (135, 5)\n",
      "2025-09-06 18:54:38,955 INFO: Retornando DataFrame combinado: (82, 8)\n",
      "2025-09-06 18:54:38,956 INFO: Datos procesados: 82 filas, 8 columnas\n",
      "2025-09-06 18:54:38,956 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n"
     ]
    }
   ],
   "source": [
    "# 6. Procesar datos para entrenamiento\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "try:\n",
    "       \n",
    "    # Procesar datos usando la función mejorada que acepta tuplas directamente\n",
    "    features_and_target = transformar_features_target(\n",
    "        df_ts,\n",
    "        lags_list=[1, 2, 3, 52], \n",
    "        columna_target='base_imponible',\n",
    "        cols_exogenas=['is_easter', 'is_summer_peak'],\n",
    "        periodos_adelante=1,\n",
    "        eliminar_nulos=True,\n",
    "        return_format='dataframe'  # Obtenemos un único DataFrame con features y target\n",
    "    )\n",
    "    \n",
    "    # Mostrar información de los datos procesados\n",
    "    logger.info(f\"Datos procesados: {features_and_target.shape[0]} filas, {features_and_target.shape[1]} columnas\")\n",
    "    logger.info(f\"Variables disponibles: {list(features_and_target.columns)}\")\n",
    "    print(\"\\nMuestra de datos procesados:\")\n",
    "    print(features_and_target.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al procesar datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad845d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 218.2798, 'rmse': 286.1179, 'mape': 0.2023, 'r2': 0.3658}\n"
     ]
    }
   ],
   "source": [
    "# 7. Split temporal y entrenamiento con XGBoost\n",
    "from src.data_split import train_test_split\n",
    "from src.model import train_evaluate_xgboost\n",
    "\n",
    "try:\n",
    "    # Split temporal usando el 80% para train\n",
    "    split_idx = int(len(features_and_target) * 0.8)\n",
    "    split_date = features_and_target.loc[split_idx, 'week_start']\n",
    "    X_train, y_train, X_test, y_test = train_test_split(\n",
    "        features_and_target,\n",
    "        split_date=split_date,\n",
    "        target= 'target'  # o 'base_imponible' según tu pipeline\n",
    "    )\n",
    "\n",
    "    # Entrenamiento y evaluación\n",
    "    resultados = train_evaluate_xgboost(X_train, y_train, X_test, y_test)\n",
    "    print({k: (round(v,4) if isinstance(v, float) else v) for k,v in resultados.items() if k != 'model'})\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Entrenamiento XGBoost falló: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50726f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Workspace\\\\mlops_fleca_project\\\\models\\\\xgboost_hopsworks.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Guardar el modelo entrenado\n",
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "joblib.dump(resultados['model'], MODELS_DIR / 'xgboost_hopsworks.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6df2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "# cargamos el modelo\n",
    "model = joblib.load(MODELS_DIR / 'xgboost_hopsworks.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4456134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0427a0d53894b36b9428dc66e5de09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00f357d44664b6bac9421ed2c6536fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading C:\\Workspace\\mlops_fleca_project\\models\\xgboost_hopsworks.pkl: 0.000%|          | 0/83595 elapsed<00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d502300e141e4a72b4f4479329e0ce5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Workspace\\mlops_fleca_project\\notebooks\\input_example.json: 0.000%|          | 0/70 elapsed<00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268689f5a05d4eed9026d30e474d8417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Workspace\\mlops_fleca_project\\notebooks\\model_schema.json: 0.000%|          | 0/782 elapsed<00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1242272/models/fleca_bolleria_predictor_next_week/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'fleca_bolleria_predictor_next_week', version: 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Registro del modelo (Model registry)\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Crear esquemas de entrada y salida para el modelo\n",
    "# Esquema de datos\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Esquema del modelo\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Eliminar columnas datetime no soportadas por XGBoost\n",
    "X_test_model = X_test.drop(columns=['week_start'], errors='ignore')\n",
    "\n",
    "# Realizar predicción con el modelo entrenado\n",
    "y_pred_xgb = resultados['model'].predict(X_test_model)\n",
    "\n",
    "# Calcular MAE\n",
    "test_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Obtener el model registry de Hopsworks\n",
    "model_registry = project.get_model_registry()\n",
    "\n",
    "# Registrar el modelo en Hopsworks\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"fleca_bolleria_predictor_next_week\",\n",
    "    description=\"Modelo XGBoost para predecir la base imponible de bollería la próxima semana\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema,\n",
    "    metrics={\"mae\": test_mae}\n",
    "    )\n",
    "\n",
    "# Guardar el modelo localmente (convertir ruta a string para evitar AttributeError)\n",
    "model.save(str(MODELS_DIR / 'xgboost_hopsworks.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
