{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fecha",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "familia",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unidades_vendidas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "base_imponible",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5612bbd3-350e-4718-ad76-03eee8e64046",
       "rows": [
        [
         "0",
         "2023-11-09 00:00:00",
         "PAN",
         "1.0",
         null,
         null
        ],
        [
         "1",
         "2023-11-07 00:00:00",
         "PAN",
         "1.0",
         null,
         null
        ],
        [
         "2",
         "2023-11-08 00:00:00",
         "PAN",
         "1.0",
         null,
         null
        ],
        [
         "3",
         "2023-07-24 00:00:00",
         "PAN",
         "0.8",
         "0.06",
         "0.06"
        ],
        [
         "4",
         "2023-08-13 00:00:00",
         "PAN",
         "1.0",
         "0.08",
         "0.08"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>familia</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>base_imponible</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>PAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>PAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>PAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>PAN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>PAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha familia  unidades_vendidas  base_imponible  total\n",
       "0 2023-11-09     PAN                1.0             NaN    NaN\n",
       "1 2023-11-07     PAN                1.0             NaN    NaN\n",
       "2 2023-11-08     PAN                1.0             NaN    NaN\n",
       "3 2023-07-24     PAN                0.8            0.06   0.06\n",
       "4 2023-08-13     PAN                1.0            0.08   0.08"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = '../data/interim/df_fleca'\n",
    "df_fleca = pd.read_parquet(file_path)\n",
    "df_fleca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fecha",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "familia",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "unidades_vendidas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "base_imponible",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "56aea52f-9679-45b1-917d-ccf7f0b67a43",
       "rows": [
        [
         "count",
         "295979",
         "295978",
         "295979.0",
         "293732.0",
         "293732.0"
        ],
        [
         "unique",
         null,
         "16",
         null,
         null,
         null
        ],
        [
         "top",
         null,
         "CAFES",
         null,
         null,
         null
        ],
        [
         "freq",
         null,
         "114569",
         null,
         null,
         null
        ],
        [
         "mean",
         "2024-01-12 01:52:50.037063168",
         null,
         "1.2056258484554647",
         "2.0024293233287485",
         "2.188847112333692"
        ],
        [
         "min",
         "2023-01-02 00:00:00",
         null,
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "2023-07-10 00:00:00",
         null,
         "1.0",
         "1.32",
         "1.4"
        ],
        [
         "50%",
         "2023-12-27 00:00:00",
         null,
         "1.0",
         "1.55",
         "1.7"
        ],
        [
         "75%",
         "2024-07-25 00:00:00",
         null,
         "1.0",
         "2.27",
         "2.5"
        ],
        [
         "max",
         "2025-02-28 00:00:00",
         null,
         "93.0",
         "287.27",
         "316.0"
        ],
        [
         "std",
         null,
         null,
         "0.738732395366282",
         "1.7194260428808106",
         "1.891815258058564"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>familia</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>base_imponible</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>295979</td>\n",
       "      <td>295978</td>\n",
       "      <td>295979.000000</td>\n",
       "      <td>293732.000000</td>\n",
       "      <td>293732.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CAFES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>114569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024-01-12 01:52:50.037063168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.205626</td>\n",
       "      <td>2.002429</td>\n",
       "      <td>2.188847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-07-10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2023-12-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-07-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-02-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>287.270000</td>\n",
       "      <td>316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.738732</td>\n",
       "      <td>1.719426</td>\n",
       "      <td>1.891815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fecha familia  unidades_vendidas  \\\n",
       "count                          295979  295978      295979.000000   \n",
       "unique                            NaN      16                NaN   \n",
       "top                               NaN   CAFES                NaN   \n",
       "freq                              NaN  114569                NaN   \n",
       "mean    2024-01-12 01:52:50.037063168     NaN           1.205626   \n",
       "min               2023-01-02 00:00:00     NaN           0.000000   \n",
       "25%               2023-07-10 00:00:00     NaN           1.000000   \n",
       "50%               2023-12-27 00:00:00     NaN           1.000000   \n",
       "75%               2024-07-25 00:00:00     NaN           1.000000   \n",
       "max               2025-02-28 00:00:00     NaN          93.000000   \n",
       "std                               NaN     NaN           0.738732   \n",
       "\n",
       "        base_imponible          total  \n",
       "count    293732.000000  293732.000000  \n",
       "unique             NaN            NaN  \n",
       "top                NaN            NaN  \n",
       "freq               NaN            NaN  \n",
       "mean          2.002429       2.188847  \n",
       "min           0.000000       0.000000  \n",
       "25%           1.320000       1.400000  \n",
       "50%           1.550000       1.700000  \n",
       "75%           2.270000       2.500000  \n",
       "max         287.270000     316.000000  \n",
       "std           1.719426       1.891815  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos las estadísticas descriptivas de las columnas numéricas\n",
    "df_fleca.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 295979 entries, 0 to 295978\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   fecha              295979 non-null  datetime64[ns]\n",
      " 1   familia            295978 non-null  object        \n",
      " 2   unidades_vendidas  295979 non-null  float64       \n",
      " 3   base_imponible     293732 non-null  float64       \n",
      " 4   total              293732 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(1)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la estructura y tipos de datos\n",
    "df_fleca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después de la imputación:\n",
      "fecha                0\n",
      "familia              1\n",
      "unidades_vendidas    0\n",
      "base_imponible       0\n",
      "total                0\n",
      "mes                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos en las columnas 'total' y 'base_imponible'\n",
    "\n",
    "def imputar_valores_nulos(df: pd.DataFrame, meses_cercanos: list[str], mes_objetivo: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Imputa valores nulos en las columnas 'total' y 'base_imponible' utilizando la media\n",
    "    de los meses más cercanos y, si es necesario, la media anual por familia.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'fecha', 'familia', 'total' y 'base_imponible'.\n",
    "        meses_cercanos (list[str]): Lista de meses cercanos (en formato 'YYYY-MM') para calcular la media.\n",
    "        mes_objetivo (str): Mes objetivo (en formato 'YYYY-MM') donde se imputarán los valores nulos.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los valores nulos imputados.\n",
    "    \"\"\"\n",
    "    # Validación de columnas requeridas\n",
    "    required_columns = {'fecha', 'familia', 'total', 'base_imponible'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"El DataFrame debe contener las columnas: {required_columns}\")\n",
    "    \n",
    "    # Asegurar que 'fecha' es de tipo datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['fecha']):\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    \n",
    "    # Copiar el DataFrame para evitar modificar el original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convertir 'fecha' a Periodo (mes-año) para facilitar la agrupación\n",
    "    df['mes'] = df['fecha'].dt.to_period('M')\n",
    "    \n",
    "    # Lista de columnas a imputar\n",
    "    columnas = ['total', 'base_imponible']\n",
    "    \n",
    "    # Imputar valores nulos utilizando la media de meses cercanos\n",
    "    for col in columnas:\n",
    "        for categoria in df['familia'].unique():\n",
    "            for mes in meses_cercanos:\n",
    "                # Calcular la media para la categoría y mes actual\n",
    "                media = df.loc[\n",
    "                    (df['familia'] == categoria) & (df['mes'] == mes), col\n",
    "                ].mean()\n",
    "                # Imputar valores nulos en el mes objetivo para la columna actual\n",
    "                df.loc[\n",
    "                    (df['familia'] == categoria) &\n",
    "                    (df['mes'] == mes_objetivo) &\n",
    "                    (df[col].isnull()),\n",
    "                    col\n",
    "                ] = media\n",
    "        \n",
    "        # Para los valores nulos restantes, imputar con la media anual por familia\n",
    "        mask_obj = df['mes'] == mes_objetivo\n",
    "        df.loc[mask_obj, col] = df.groupby('familia')[col].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "    \n",
    "    # Mostrar resumen de valores nulos (opcional)\n",
    "    print(\"Valores nulos después de la imputación:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Definir los meses cercanos y el mes objetivo\n",
    "meses_cercanos = [\"2023-10\", \"2023-12\"]\n",
    "mes_objetivo = \"2023-11\"\n",
    "\n",
    "# Llamar a la función para imputar valores nulos\n",
    "df_fleca = imputar_valores_nulos(df_fleca, meses_cercanos, mes_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después de eliminar filas:\n",
      "fecha                0\n",
      "familia              0\n",
      "unidades_vendidas    0\n",
      "base_imponible       0\n",
      "total                0\n",
      "mes                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def eliminar_filas_nulas_familia(df_fleca: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina las filas del DataFrame que contienen valores nulos en la columna 'familia'\n",
    "    y muestra la información del DataFrame resultante.\n",
    "\n",
    "    Args:\n",
    "        df_fleca (pd.DataFrame): DataFrame que contiene la columna 'familia'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame sin filas con valores nulos en la columna 'familia'.\n",
    "    \"\"\"\n",
    "    df_fleca = df_fleca.dropna(subset=['familia'], how='any')\n",
    "    print(\"Valores nulos después de eliminar filas:\")\n",
    "    print(df_fleca.isnull().sum())\n",
    "        \n",
    "    return df_fleca\n",
    "\n",
    "# Para ver los resultados:\n",
    "df_fleca = eliminar_filas_nulas_familia(df_fleca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vista previa del DataFrame con indicadores de festivos y Semana Santa:\n",
      "           familia  unidades_vendidas  base_imponible     total      mes  \\\n",
      "fecha                                                                      \n",
      "2023-11-09     PAN                1.0        1.356664  1.362142  2023-11   \n",
      "2023-11-07     PAN                1.0        1.356664  1.362142  2023-11   \n",
      "2023-11-08     PAN                1.0        1.356664  1.362142  2023-11   \n",
      "2023-07-24     PAN                0.8        0.060000  0.060000  2023-07   \n",
      "2023-08-13     PAN                1.0        0.080000  0.080000  2023-08   \n",
      "\n",
      "            semana_santa  festivo  \n",
      "fecha                              \n",
      "2023-11-09         False    False  \n",
      "2023-11-07         False    False  \n",
      "2023-11-08         False    False  \n",
      "2023-07-24         False    False  \n",
      "2023-08-13         False    False  \n",
      "Registros eliminados por ser outliers fuera de Semana Santa: 6\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "def procesar_festivos_semana_santa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Procesa el DataFrame agregando indicadores de festivos y Semana Santa, \n",
    "    y filtra los outliers en la columna 'total' (excluyendo transacciones de Semana Santa).\n",
    "\n",
    "    El procesamiento incluye:\n",
    "      - Definir fechas festivas.\n",
    "      - Definir rangos para Semana Santa (2023, 2024 y 2025) y combinarlos.\n",
    "      - Agregar columnas indicando si la fecha (en el índice) es festivo o corresponde a Semana Santa.\n",
    "      - Marcar las transacciones que ocurren en Semana Santa según la columna 'fecha'.\n",
    "      - Filtrar los registros con 'total' > 50 que no correspondan a Semana Santa.\n",
    "      - Mostrar la cantidad de registros eliminados.\n",
    "      - Limpiar el DataFrame eliminando columnas auxiliares.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame que debe contener al menos la columna 'fecha' (tipo datetime) y 'total'.\n",
    "                           Se asume que el índice es de tipo DatetimeIndex para la imputación de festivos y Semana Santa.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame procesado.\n",
    "    \"\"\"\n",
    "    # Validar que el índice sea de tipo DatetimeIndex, si no, intentar convertir la columna 'fecha' y establecerla como índice\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if 'fecha' in df.columns:\n",
    "            df = df.copy()\n",
    "            df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "            df.set_index('fecha', inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"El DataFrame debe tener un índice de tipo DatetimeIndex o una columna 'fecha'.\")\n",
    "    \n",
    "    # Definir los festivos\n",
    "    festivos = ['2023-01-01', '2023-12-25', '2024-01-01', '2024-12-25', '2025-01-01']\n",
    "    festivos = pd.to_datetime(festivos)\n",
    "    \n",
    "    # Definir rango de Semana Santa (asumiendo una duración típica)\n",
    "    semana_santa_2023 = pd.date_range('2023-04-02', '2023-04-09')\n",
    "    semana_santa_2024 = pd.date_range('2024-03-24', '2024-03-31')\n",
    "    semana_santa_2025 = pd.date_range('2025-04-13', '2025-04-20')\n",
    "    semana_santa = semana_santa_2023.union(semana_santa_2024).union(semana_santa_2025)\n",
    "    \n",
    "    # Agregar columnas indicando si el índice (fecha) corresponde a Semana Santa y festivos\n",
    "    df = df.copy()  # Evitar modificar el original\n",
    "    df['semana_santa'] = df.index.to_series().apply(lambda x: x in semana_santa)\n",
    "    df['festivo'] = df.index.to_series().apply(lambda x: x in festivos)\n",
    "    \n",
    "    # Verificar datos (opcional)\n",
    "    print(\"Vista previa del DataFrame con indicadores de festivos y Semana Santa:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Marcar si la transacción pertenece a Semana Santa según la columna 'fecha'\n",
    "    # (Se asume que existe una columna 'fecha'; si no, se puede utilizar el índice)\n",
    "    if 'fecha' in df.columns:\n",
    "        df['es_semana_santa'] = df['fecha'].isin(semana_santa)\n",
    "    else:\n",
    "        # En caso de no tener la columna 'fecha', se utiliza el índice\n",
    "        df['es_semana_santa'] = df.index.to_series().isin(semana_santa)\n",
    "    \n",
    "    # Eliminar valores extremos en 'total' solo si NO son de Semana Santa\n",
    "    df_filtrado = df[~((df['total'] > 50) & (df['es_semana_santa'] == False))]\n",
    "    \n",
    "    # Mostrar la cantidad de registros eliminados\n",
    "    registros_eliminados = df.shape[0] - df_filtrado.shape[0]\n",
    "    print(f\"Registros eliminados por ser outliers fuera de Semana Santa: {registros_eliminados}\")\n",
    "    \n",
    "    # Limpiar el DataFrame eliminando la columna auxiliar\n",
    "    df_filtrado = df_filtrado.drop(columns=['es_semana_santa'])\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "df_fleca = procesar_festivos_semana_santa(df_fleca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame agrupado por semana:\n",
      "            unidades_vendidas  base_imponible    total  semana_santa  festivo\n",
      "fecha                                                                        \n",
      "2023-01-08            3075.54         5145.61  5627.68             0        0\n",
      "2023-01-15            2569.91         4020.09  4392.67             0        0\n",
      "2023-01-22            2771.42         4406.36  4803.98             0        0\n",
      "2023-01-29            2528.31         4022.09  4397.29             0        0\n",
      "2023-02-05            2520.70         3952.34  4320.69             0        0\n"
     ]
    }
   ],
   "source": [
    "# Agrupara por semana y sumar las columnas 'total' y 'base_imponible' y 'unidades_vendidas'\n",
    "\n",
    "def agrupar_por_semana(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrupa el DataFrame por semana y suma las columnas 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'fecha', 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrupado por semana con las sumas de las columnas especificadas.\n",
    "    \"\"\"\n",
    "    # Validar que el índice sea de tipo DatetimeIndex, si no, intentar convertir la columna 'fecha' y establecerla como índice\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if 'fecha' in df.columns:\n",
    "            df = df.copy()\n",
    "            df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "            df.set_index('fecha', inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"El DataFrame debe tener un índice de tipo DatetimeIndex o una columna 'fecha'.\")\n",
    "    \n",
    "    # Agrupar por semana y sumar las columnas especificadas\n",
    "    df_semana = df.resample('W').sum(numeric_only=True)\n",
    "    \n",
    "    return df_semana\n",
    "\n",
    "df_fleca_semana = agrupar_por_semana(df_fleca)\n",
    "print(\"DataFrame agrupado por semana:\")\n",
    "print(df_fleca_semana.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame agrupado por semana guardado en: C:\\Workspace\\mlops_fleca_project\\data\\df_fleca_semana.parquet\n"
     ]
    }
   ],
   "source": [
    "# Almacenar el DataFrame agrupado en un archivo parquet en la carpeta interim (datos intermedios) por semanas\n",
    "\n",
    "carpeta = Path(\"C:/Workspace/mlops_fleca_project/data\")\n",
    "(carpeta / \"interim\").mkdir(parents=True, exist_ok=True)\n",
    "df_fleca_semana.to_parquet(carpeta / \"interim\" / \"df_fleca_semana.parquet\")\n",
    "print(f\"DataFrame agrupado por semana guardado en: {carpeta / 'df_fleca_semana.parquet'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame agrupado por semana y con columna 'semana' convertida a datetime:\n",
      "      semana    total  base_imponible  unidades_vendidas\n",
      "0 2023-01-08  5627.68         5145.61            3075.54\n",
      "1 2023-01-15  4392.67         4020.09            2569.91\n",
      "2 2023-01-22  4803.98         4406.36            2771.42\n",
      "3 2023-01-29  4397.29         4022.09            2528.31\n",
      "4 2023-02-05  4320.69         3952.34            2520.70\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos por semana y sumamos las columnas 'total', 'base_imponible' y 'unidades_vendidas'\n",
    "# y reiniciamos el índice\n",
    "# y convertimos la columna 'fecha' a tipo datetime\n",
    "\n",
    "def agrupar_por_semana_y_sumar(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrupa el DataFrame por semana y suma las columnas 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "    Reinicia el índice y convierte la columna de semana a tipo datetime.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'fecha', 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrupado por semana con las sumas de las columnas especificadas.\n",
    "    \"\"\"\n",
    "    # Agrupar por semana usando el índice DatetimeIndex\n",
    "    df_grouped = df.resample('W')[['total', 'base_imponible', 'unidades_vendidas']].sum().reset_index()\n",
    "    df_grouped.rename(columns={'fecha': 'semana'}, inplace=True)\n",
    "    return df_grouped\n",
    "\n",
    "df_fleca_semana = agrupar_por_semana_y_sumar(df_fleca)\n",
    "print(\"DataFrame agrupado por semana y con columna 'semana' convertida a datetime:\")\n",
    "print(df_fleca_semana.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar el DataFrame agrupado en un archivo parquet en la carpeta interim (datos intermedios)\n",
    "output_path = Path('../data/interim/df_fleca_semana')\n",
    "df_fleca_semana.to_parquet(output_path, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame agrupado por familia y semana:\n",
      "      semana     familia   total  base_imponible  unidades_vendidas\n",
      "0 2023-01-02    AÑADIDOS    9.60            8.81              33.00\n",
      "1 2023-01-02      BEBIDA  157.55          143.01              98.00\n",
      "2 2023-01-02     BEBIDAS  357.45          324.95             149.00\n",
      "3 2023-01-02  BOCADILLOS  950.40          864.03             380.00\n",
      "4 2023-01-02    BOLLERIA  907.13          825.11             631.89\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por familia y semana, y calcular la suma de 'total', 'base_imponible' y unidades_vendidas\n",
    "def agrupar_por_semana_y_familia(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrupa el DataFrame por familia y semana, y calcula la suma de 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'fecha', 'familia', 'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrupado por familia y semana con las sumas de las columnas especificadas.\n",
    "    \"\"\"\n",
    "    # Validar que el índice sea de tipo DatetimeIndex, si no, intentar convertir la columna 'fecha' y establecerla como índice\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if 'fecha' in df.columns:\n",
    "            df = df.copy()\n",
    "            df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "            df.set_index('fecha', inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"El DataFrame debe tener un índice de tipo DatetimeIndex o una columna 'fecha'.\")\n",
    "    \n",
    "    # Agrupar por semana y familia usando el índice DatetimeIndex (por semana natural)\n",
    "    df_grouped = df.copy()\n",
    "    df_grouped['semana'] = df_grouped.index.to_period('W').to_timestamp()\n",
    "    df_grouped = df_grouped.groupby(['semana', 'familia'])[['total', 'base_imponible', 'unidades_vendidas']].sum().reset_index()\n",
    "    return df_grouped\n",
    "\n",
    "df_fleca_semana_familia = agrupar_por_semana_y_familia(df_fleca)\n",
    "print(\"DataFrame agrupado por familia y semana:\")\n",
    "print(df_fleca_semana_familia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      semana     familia   total  base_imponible  unidades_vendidas\n",
      "0 2023-01-02    AÑADIDOS    9.60            8.81              33.00\n",
      "1 2023-01-02      BEBIDA  157.55          143.01              98.00\n",
      "2 2023-01-02     BEBIDAS  357.45          324.95             149.00\n",
      "3 2023-01-02  BOCADILLOS  950.40          864.03             380.00\n",
      "4 2023-01-02    BOLLERIA  907.13          825.11             631.89\n"
     ]
    }
   ],
   "source": [
    "# Almacenar el DataFrame agrupado en un archivo parquet en la carpeta interim (datos intermedios)\n",
    "carpeta = Path(\"c:/Workspace/mlops_fleca_project/data\")\n",
    "df_fleca_semana_familia.to_parquet(carpeta / \"interim\" / \"df_fleca_semana_family\", index=False)\n",
    "print(df_fleca_semana_familia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mes     total  base_imponible  unidades_vendidas\n",
      "0 2023-01-01  20361.41        18636.70           11625.88\n",
      "1 2023-02-01  17444.14        15959.63           10205.77\n",
      "2 2023-03-01  21301.03        19475.63           12286.30\n",
      "3 2023-04-01  28905.01        26450.90           16008.64\n",
      "4 2023-05-01  25389.64        23209.71           14379.80\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos por mes y sumamos las columnas 'total', 'base_imponible' y 'unidades_vendidas'\n",
    "# y reiniciamos el índice\n",
    "# y convertimos la columna 'mes' a formato Timestamp    \n",
    "\n",
    "def agrupar_por_mes_y_sumar(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrupa el DataFrame por la columna 'mes' y suma las columnas 'total', 'base_imponible'\n",
    "    y 'unidades_vendidas'. Además, reinicia el índice y convierte la columna 'mes' a formato Timestamp.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame que contiene la columna 'mes' (de tipo Period) y las columnas\n",
    "                           'total', 'base_imponible' y 'unidades_vendidas'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrupado por mes con las sumas correspondientes.\n",
    "    \"\"\"\n",
    "    df_grouped = df.groupby(df['mes'])[['total', 'base_imponible', 'unidades_vendidas']].sum()\n",
    "    df_grouped.reset_index(inplace=True)\n",
    "    df_grouped['mes'] = df_grouped['mes'].dt.to_timestamp()\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "df_fleca_monthly = agrupar_por_mes_y_sumar(df_fleca)\n",
    "print(df_fleca_monthly.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar el DataFrame agrupado en un archivo parquet en la carpeta interim (datos intermedios)\n",
    "\n",
    "carpeta = Path(\"D:/Workspace/mlops_fleca_project/data\")\n",
    "(carpeta / \"interim\").mkdir(parents=True, exist_ok=True)\n",
    "df_fleca_monthly.to_parquet(carpeta / \"interim\" / \"df_fleca_monthly\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí, ya no sirve (lo dejo como histórico por si lo necesito para ver algo más adelante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mes     familia    total  base_imponible  unidades_vendidas\n",
      "0 2023-01-01    AÑADIDOS    37.15           34.06             107.00\n",
      "1 2023-01-01      BEBIDA   624.60          567.09             378.00\n",
      "2 2023-01-01     BEBIDAS  1347.90         1225.37             552.00\n",
      "3 2023-01-01  BOCADILLOS  3560.20         3236.15            1374.00\n",
      "4 2023-01-01    BOLLERIA  3350.27         3047.58            2237.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def agrupar_por_mes_y_familia(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrupa el DataFrame por 'mes' y 'familia', sumando las columnas 'total', 'base_imponible'\n",
    "    y 'unidades_vendidas'. Reinicia el índice y convierte la columna 'mes' de Period a Timestamp.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame que contiene las columnas 'mes', 'familia', 'total',\n",
    "                           'base_imponible' y 'unidades_vendidas'. Se asume que la columna 'mes'\n",
    "                           es de tipo Period.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame agrupado por 'mes' y 'familia' con las sumas correspondientes.\n",
    "    \"\"\"\n",
    "    df_grouped = df.groupby(['mes', 'familia'])[['total', 'base_imponible', 'unidades_vendidas']].sum()\n",
    "    df_grouped.reset_index(inplace=True)\n",
    "    df_grouped['mes'] = df_grouped['mes'].dt.to_timestamp()\n",
    "    return df_grouped\n",
    "\n",
    "df_fleca_monthly_family = agrupar_por_mes_y_familia(df_fleca)\n",
    "print(df_fleca_monthly_family.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mes     familia    total  base_imponible  unidades_vendidas\n",
      "0 2023-01-01    AÑADIDOS    37.15           34.06             107.00\n",
      "1 2023-01-01      BEBIDA   624.60          567.09             378.00\n",
      "2 2023-01-01     BEBIDAS  1347.90         1225.37             552.00\n",
      "3 2023-01-01  BOCADILLOS  3560.20         3236.15            1374.00\n",
      "4 2023-01-01    BOLLERIA  3350.27         3047.58            2237.88\n"
     ]
    }
   ],
   "source": [
    "# Almacenar el DataFrame agrupado en un archivo parquet en la carpeta interim (datos intermedios)\n",
    "\n",
    "carpeta = Path(\"D:/Workspace/mlops_fleca_project/data\")\n",
    "df_fleca_monthly_family.to_parquet(carpeta / \"interim\" / \"df_fleca_monthly_family\", index=False)\n",
    "print(df_fleca_monthly_family.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
