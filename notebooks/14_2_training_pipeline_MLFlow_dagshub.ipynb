{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39a6788",
   "metadata": {},
   "source": [
    "# üöÄ Pipeline de Entrenamiento MLflow + DagsHub\n",
    "\n",
    "Este notebook implementa un pipeline completo de entrenamiento de modelos de Machine Learning con las siguientes funcionalidades:\n",
    "\n",
    "## üìã Objetivos\n",
    "- **Conexi√≥n a Hopsworks**: Obtener datos desde el Feature Store\n",
    "- **Procesamiento de datos**: Transformar caracter√≠sticas y crear conjuntos de entrenamiento/test\n",
    "- **Configuraci√≥n MLflow**: Tracking de experimentos con backend DagsHub\n",
    "- **Entrenamiento de modelos**: M√∫ltiples algoritmos (Linear, RandomForest, XGBoost, etc.)\n",
    "- **Evaluaci√≥n y comparaci√≥n**: Encontrar el mejor modelo por MAE\n",
    "- **Carga de modelos**: Sistema robusto para cargar el mejor modelo entrenado\n",
    "\n",
    "## üõ†Ô∏è Tecnolog√≠as\n",
    "- **Hopsworks**: Feature Store para gesti√≥n de datos\n",
    "- **MLflow**: Tracking de experimentos y gesti√≥n de modelos  \n",
    "- **DagsHub**: Backend remoto para MLflow\n",
    "- **Scikit-learn**: Modelos de ML\n",
    "- **XGBoost**: Gradient boosting\n",
    "\n",
    "## üîÑ Flujo del Pipeline\n",
    "1. Configuraci√≥n e importaciones\n",
    "2. Conexi√≥n a Hopsworks Feature Store\n",
    "3. Obtenci√≥n y procesamiento de datos\n",
    "4. Configuraci√≥n MLflow + DagsHub\n",
    "5. Entrenamiento de modelos m√∫ltiples\n",
    "6. Evaluaci√≥n y selecci√≥n del mejor modelo\n",
    "7. Carga robusta del modelo ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5c4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from dagshub import dagshub_logger, init\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±ade src al path para importar los m√≥dulos\n",
    "sys.path.append(str(Path().resolve().parent / 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303b643",
   "metadata": {},
   "source": [
    "## 1. üîß Configuraci√≥n e Importaciones\n",
    "\n",
    "Configuraci√≥n inicial del entorno, importaciones necesarias y configuraci√≥n de logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e412d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243a14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n b√°sica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('feature_view_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddad7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:08,561 INFO: Initializing external client\n",
      "2025-09-02 17:54:08,562 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-09-02 17:54:08,562 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:09,945 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "2025-09-02 17:54:11,203 INFO: Conexi√≥n exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n",
      "2025-09-02 17:54:11,203 INFO: Conexi√≥n exitosa al Feature Group: times_series_bolleria_feature_group (v1)\n"
     ]
    }
   ],
   "source": [
    "# Conectar a Hopsworks y al Feature Store\n",
    "try:\n",
    "    # Login y conexi√≥n al proyecto\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=config.HOPSWORKS_API_KEY, \n",
    "        project=config.HOPSWORKS_PROJECT_NAME)\n",
    "    \n",
    "    # Conexi√≥n al feature store\n",
    "    feature_store = project.get_feature_store()\n",
    "    \n",
    "    # Conexi√≥n al feature group\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Conexi√≥n exitosa al Feature Group: {feature_group.name} (v{feature_group.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en conexi√≥n: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ff772",
   "metadata": {},
   "source": [
    "## 2. üè™ Conexi√≥n a Hopsworks Feature Store\n",
    "\n",
    "Conexi√≥n al Feature Store de Hopsworks para obtener los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc46d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:12,077 INFO: Feature view existente recuperada: times_series_bolleria_feature_view (v1)\n"
     ]
    }
   ],
   "source": [
    "# Crear/obtener feature view con caracter√≠sticas seleccionadas\n",
    "try:\n",
    "    # Caracter√≠sticas espec√≠ficas a incluir\n",
    "    selected_features = ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
    "    feature_view_name = config.FEATURE_VIEW_NAME\n",
    "    feature_view_version = 1\n",
    "    \n",
    "    # Intentar obtener la feature view existente primero\n",
    "    try:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version\n",
    "        )\n",
    "        logger.info(f\"Feature view existente recuperada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "    except:\n",
    "        # Si no existe, crear una nueva\n",
    "        # Obtener objetos Feature para las caracter√≠sticas seleccionadas\n",
    "        selected_feature_objects = [f for f in feature_group.features if f.name in selected_features]\n",
    "        \n",
    "        # Crear query con caracter√≠sticas seleccionadas\n",
    "        specific_query = feature_group.select(selected_feature_objects)\n",
    "        \n",
    "        # Crear la feature view\n",
    "        feature_view = feature_store.create_feature_view(\n",
    "            name=feature_view_name,\n",
    "            version=feature_view_version,\n",
    "            query=specific_query,\n",
    "            description=f\"Feature view con caracter√≠sticas: {', '.join(selected_features)}\"\n",
    "        )\n",
    "        logger.info(f\"Nueva feature view creada: {feature_view.name} (v{feature_view.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al crear/obtener feature view: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb477b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.71s) \n",
      "2025-09-02 17:54:15,565 INFO: Datos obtenidos: 133 filas, 5 columnas\n",
      "2025-09-02 17:54:15,566 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.71s) \n",
      "2025-09-02 17:54:15,565 INFO: Datos obtenidos: 133 filas, 5 columnas\n",
      "2025-09-02 17:54:15,566 INFO: Columnas disponibles: ['familia', 'base_imponible', 'is_summer_peak', 'is_easter', 'week_start']\n",
      "Muestra de datos:\n",
      "    familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  BOLLERIA          641.56               0          0   \n",
      "1  BOLLERIA          725.72               0          0   \n",
      "2  BOLLERIA          950.70               0          0   \n",
      "\n",
      "                 week_start  \n",
      "0 2023-02-06 00:00:00+00:00  \n",
      "1 2025-02-24 00:00:00+00:00  \n",
      "2 2023-09-18 00:00:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Obtener datos de la feature view\n",
    "try:\n",
    "    # Obtener datos en batch normal\n",
    "    df_ts = feature_view.get_batch_data()\n",
    "    \n",
    "    # Mostrar resumen de los datos obtenidos\n",
    "    logger.info(f\"Datos obtenidos: {df_ts.shape[0]} filas, {df_ts.shape[1]} columnas\")\n",
    "    logger.info(f\"Columnas disponibles: {list(df_ts.columns)}\")\n",
    "    print(\"Muestra de datos:\")\n",
    "    print(df_ts.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al obtener datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f1a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.71s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.71s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `46`.\n"
     ]
    }
   ],
   "source": [
    "# Obtener datos de entrenamiento (training_data)\n",
    "try:\n",
    "    # Obtener datos de entrenamiento (X, y) desde la feature view\n",
    "    df_ts = feature_view.training_data()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al obtener datos de entrenamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09821c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:19,314 INFO: Detectada entrada tipo tupla con 2 elementos\n",
      "2025-09-02 17:54:19,314 INFO: Usando el primer elemento de la tupla como DataFrame: (133, 5)\n",
      "2025-09-02 17:54:19,322 INFO: Retornando DataFrame combinado: (80, 8)\n",
      "2025-09-02 17:54:19,322 INFO: Datos procesados: 80 filas, 8 columnas\n",
      "2025-09-02 17:54:19,323 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n",
      "2025-09-02 17:54:19,314 INFO: Usando el primer elemento de la tupla como DataFrame: (133, 5)\n",
      "2025-09-02 17:54:19,322 INFO: Retornando DataFrame combinado: (80, 8)\n",
      "2025-09-02 17:54:19,322 INFO: Datos procesados: 80 filas, 8 columnas\n",
      "2025-09-02 17:54:19,323 INFO: Variables disponibles: ['base_imponible_lag1', 'base_imponible_lag2', 'base_imponible_lag3', 'base_imponible_lag52', 'is_easter', 'is_summer_peak', 'week_start', 'target']\n",
      "\n",
      "Muestra de datos procesados:\n",
      "     base_imponible_lag1  base_imponible_lag2  base_imponible_lag3  \\\n",
      "41                572.51               534.79               563.18   \n",
      "72                597.65               572.51               534.79   \n",
      "114               680.30               597.65               572.51   \n",
      "\n",
      "     base_imponible_lag52  is_easter  is_summer_peak  \\\n",
      "41                 825.11          0               0   \n",
      "72                 658.40          0               0   \n",
      "114                741.40          0               0   \n",
      "\n",
      "                   week_start  target  \n",
      "41  2024-01-15 00:00:00+00:00  680.30  \n",
      "72  2024-01-22 00:00:00+00:00  603.99  \n",
      "114 2024-01-29 00:00:00+00:00  600.14  \n"
     ]
    }
   ],
   "source": [
    "# Procesar datos para entrenamiento\n",
    "from src.data_utils import transformar_features_target\n",
    "\n",
    "try:\n",
    "       \n",
    "    # Procesar datos usando la funci√≥n mejorada que acepta tuplas directamente\n",
    "    features_and_target = transformar_features_target(\n",
    "        df_ts,\n",
    "        lags_list=[1, 2, 3, 52], \n",
    "        columna_target='base_imponible',\n",
    "        cols_exogenas=['is_easter', 'is_summer_peak'],\n",
    "        periodos_adelante=1,\n",
    "        eliminar_nulos=True,\n",
    "        return_format='dataframe'  # Obtenemos un √∫nico DataFrame con features y target\n",
    "    )\n",
    "    \n",
    "    # Mostrar informaci√≥n de los datos procesados\n",
    "    logger.info(f\"Datos procesados: {features_and_target.shape[0]} filas, {features_and_target.shape[1]} columnas\")\n",
    "    logger.info(f\"Variables disponibles: {list(features_and_target.columns)}\")\n",
    "    print(\"\\nMuestra de datos procesados:\")\n",
    "    print(features_and_target.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error al procesar datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb0b3a",
   "metadata": {},
   "source": [
    "## 3. üîÑ Procesamiento de Datos\n",
    "\n",
    "Transformaci√≥n de caracter√≠sticas, creaci√≥n de variables lag y divisi√≥n en conjuntos de entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6418c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (65, 7), Test: (15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Split temporal (autom√°tico 80/20 ya incluido en la funci√≥n)\n",
    "from src.data_split import train_test_split\n",
    "\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = train_test_split(\n",
    "        features_and_target,\n",
    "        target='target'  # o 'base_imponible' seg√∫n tu pipeline\n",
    "        # split_ratio=0.8  # puedes cambiar el porcentaje si lo necesitas\n",
    "    )\n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error en el split temporal: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54263c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas datetime antes de entrenar\n",
    "for df in [X_train, X_test]:\n",
    "    if 'week_start' in df.columns:\n",
    "        df.drop('week_start', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0bf4",
   "metadata": {},
   "source": [
    "## 4. üìä Configuraci√≥n MLflow + DagsHub\n",
    "\n",
    "Configuraci√≥n del tracking de experimentos con MLflow usando DagsHub como backend remoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb1f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:19,917 INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as joquifer2\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as joquifer2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:19,927 INFO: Accessing as joquifer2\n",
      "2025-09-02 17:54:20,199 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/joquifer2/mlops_fleca_project \"HTTP/1.1 200 OK\"\n",
      "2025-09-02 17:54:20,199 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/joquifer2/mlops_fleca_project \"HTTP/1.1 200 OK\"\n",
      "2025-09-02 17:54:20,383 INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n",
      "2025-09-02 17:54:20,383 INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"joquifer2/mlops_fleca_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"joquifer2/mlops_fleca_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:20,386 INFO: Initialized MLflow to track repo \"joquifer2/mlops_fleca_project\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository joquifer2/mlops_fleca_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository joquifer2/mlops_fleca_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:54:20,387 INFO: Repository joquifer2/mlops_fleca_project initialized!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/5024cd21a4ba41be8e29da0a760140c9', creation_time=1756810934638, experiment_id='3', last_update_time=1756810934638, lifecycle_stage='active', name='fleca_bolleria_experiments_v2', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='joquifer2', repo_name='mlops_fleca_project', mlflow=True)\n",
    "\n",
    "# Opcional: Configuraci√≥n de seguimiento de experimentos\n",
    "mlflow.set_experiment(\"fleca_bolleria_experiments_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd047d",
   "metadata": {},
   "source": [
    "## 5. ü§ñ Entrenamiento de Modelos\n",
    "\n",
    "Entrenamiento de m√∫ltiples algoritmos de ML y registro de m√©tricas en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf70eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los modelos a entrenar\n",
    "\n",
    "models ={\n",
    "    \"LinearRegresion\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"RandomForest10\": RandomForestRegressor(n_estimators=100),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5776d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LinearRegresion guardado como artefacto - MAE: 205.51 - Run ID: ac79f950067d4b7d86979647d2b8ad07\n",
      "2025-09-02 17:54:22,818 INFO: Modelo: LinearRegresion - MAE: 205.51486658938077, MSE: 63302.69911598183, R2: 0.30649562972125177\n",
      "üèÉ View run LinearRegresion at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/ac79f950067d4b7d86979647d2b8ad07\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "üèÉ View run LinearRegresion at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/ac79f950067d4b7d86979647d2b8ad07\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "‚úÖ Ridge guardado como artefacto - MAE: 181.89 - Run ID: 6f205d03c8cb46938d9c771d844bdcac\n",
      "2025-09-02 17:54:26,856 INFO: Modelo: Ridge - MAE: 181.89402786424205, MSE: 53159.90578118782, R2: 0.41761366422442714\n",
      "‚úÖ Ridge guardado como artefacto - MAE: 181.89 - Run ID: 6f205d03c8cb46938d9c771d844bdcac\n",
      "2025-09-02 17:54:26,856 INFO: Modelo: Ridge - MAE: 181.89402786424205, MSE: 53159.90578118782, R2: 0.41761366422442714\n",
      "üèÉ View run Ridge at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/6f205d03c8cb46938d9c771d844bdcac\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "üèÉ View run Ridge at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/6f205d03c8cb46938d9c771d844bdcac\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "‚úÖ Lasso guardado como artefacto - MAE: 205.03 - Run ID: ac3eca7aa0f84f78a9ebda2472bf854e\n",
      "2025-09-02 17:54:35,817 INFO: Modelo: Lasso - MAE: 205.03036855412086, MSE: 63018.17331888658, R2: 0.30961271456120576\n",
      "‚úÖ Lasso guardado como artefacto - MAE: 205.03 - Run ID: ac3eca7aa0f84f78a9ebda2472bf854e\n",
      "2025-09-02 17:54:35,817 INFO: Modelo: Lasso - MAE: 205.03036855412086, MSE: 63018.17331888658, R2: 0.30961271456120576\n",
      "üèÉ View run Lasso at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/ac3eca7aa0f84f78a9ebda2472bf854e\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "üèÉ View run Lasso at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/ac3eca7aa0f84f78a9ebda2472bf854e\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "‚úÖ RandomForest10 guardado como artefacto - MAE: 174.48 - Run ID: 36e51ff774c8440e85f092c35be63fd2\n",
      "2025-09-02 17:54:44,867 INFO: Modelo: RandomForest10 - MAE: 174.48340000000024, MSE: 50005.9986852641, R2: 0.45216587740050085\n",
      "‚úÖ RandomForest10 guardado como artefacto - MAE: 174.48 - Run ID: 36e51ff774c8440e85f092c35be63fd2\n",
      "2025-09-02 17:54:44,867 INFO: Modelo: RandomForest10 - MAE: 174.48340000000024, MSE: 50005.9986852641, R2: 0.45216587740050085\n",
      "üèÉ View run RandomForest10 at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/36e51ff774c8440e85f092c35be63fd2\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n",
      "üèÉ View run RandomForest10 at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3/runs/36e51ff774c8440e85f092c35be63fd2\n",
      "üß™ View experiment at: https://dagshub.com/joquifer2/mlops_fleca_project.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos y evaluamos varios modelos a la vez\n",
    "import joblib  # Para guardar modelos scikit-learn\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Entrenamos el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        # Realizamos predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculamos las m√©tricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Registramos las m√©tricas en mlflow\n",
    "        mlflow.log_metrics({\n",
    "            \"mae\": mae,\n",
    "            \"mse\": mse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        # Registramos los hiperpar√°metros en mlflow\n",
    "        mlflow.log_params({\n",
    "            \"model\": model_name,\n",
    "            \"n_estimators\": model.n_estimators if hasattr(model, \"n_estimators\") else None,\n",
    "            \"max_depth\": model.max_depth if hasattr(model, \"max_depth\") else None,\n",
    "            \"learning_rate\": model.learning_rate if hasattr(model, \"learning_rate\") else None\n",
    "        })\n",
    "\n",
    "        # ‚úÖ SOLUCI√ìN: Guardar modelo localmente y subir como artefacto\n",
    "        try:\n",
    "            # Crear directorio temporal para el modelo\n",
    "            model_dir = f\"temp_model_{model_name}\"\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Guardar modelo con pickle\n",
    "            model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            \n",
    "            # Registrar como artefacto en MLflow\n",
    "            mlflow.log_artifacts(model_dir, \"model\")\n",
    "            \n",
    "            # Limpiar directorio temporal\n",
    "            import shutil\n",
    "            shutil.rmtree(model_dir)\n",
    "            \n",
    "            print(f\"‚úÖ {model_name} guardado como artefacto - MAE: {mae:.2f} - Run ID: {run.info.run_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error guardando {model_name}: {e}\")\n",
    "\n",
    "        logger.info(f\"Modelo: {model_name} - MAE: {mae}, MSE: {mse}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a284844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor run ID: 0     36e51ff774c8440e85f092c35be63fd2\n",
      "4     06e656762a774e97b8435a9a605ddc55\n",
      "2     6f205d03c8cb46938d9c771d844bdcac\n",
      "6     cf13b2ca47c64f468d34ebb4fb294886\n",
      "10    2d326df0ebea4db8a5ec5072d28fcf12\n",
      "12    4746935cfcb74069ac1316a8eb5db44b\n",
      "8     81c963339bcf48f393aef0bee4e35787\n",
      "1     ac3eca7aa0f84f78a9ebda2472bf854e\n",
      "5     4d5da9206f4f4eb29d3cfe546163f16c\n",
      "9     2754a0bb85b84a60a2e2bda64becc8ee\n",
      "13    433cfb25b4b444d88e9c3cbd6b87055b\n",
      "3     ac79f950067d4b7d86979647d2b8ad07\n",
      "7     0dc390a7e2a244ee986bc831670ed4c1\n",
      "11    90033ecef3404b739909348ef57da139\n",
      "14    cf4d0fe8934049ec995627d6bd19f5ba\n",
      "Name: run_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment = mlflow.get_experiment_by_name(\"fleca_bolleria_experiments_v2\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "best_run = runs.sort_values('metrics.mae')\n",
    "print(\"Mejor run ID:\", best_run.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f949d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'RandomForest_10' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Registrar el modelo en MLflow Model Registry\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandomForest_10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:129\u001b[0m, in \u001b[0;36mregister_model\u001b[1;34m(model_uri, name, await_registration_for, tags, env_pack)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister_model\u001b[39m(\n\u001b[0;32m     62\u001b[0m     model_uri,\n\u001b[0;32m     63\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     env_pack: EnvPackType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m        Version: 1\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_register_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_pack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_pack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:178\u001b[0m, in \u001b[0;36m_register_model\u001b[1;34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Otherwise check if there's a logged model with\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# name artifact_path and source_run_id run_id\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     run \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_run(run_id)\n\u001b[1;32m--> 178\u001b[0m     logged_models \u001b[38;5;241m=\u001b[39m \u001b[43m_get_logged_models_from_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_models:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a logged_model with artifact_path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mName(NOT_FOUND),\n\u001b[0;32m    184\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:293\u001b[0m, in \u001b[0;36m_get_logged_models_from_run\u001b[1;34m(source_run, model_name)\u001b[0m\n\u001b[0;32m    290\u001b[0m page_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m     logged_models_page \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msource_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO: Filter by 'source_run_id' once Databricks backend supports it\u001b[39;49;00m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     logged_models\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m    300\u001b[0m         m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m logged_models_page \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39msource_run_id \u001b[38;5;241m==\u001b[39m source_run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_models_page\u001b[38;5;241m.\u001b[39mtoken:\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\tracking\\client.py:5607\u001b[0m, in \u001b[0;36mMlflowClient.search_logged_models\u001b[1;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m   5539\u001b[0m \u001b[38;5;129m@experimental\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_logged_models\u001b[39m(\n\u001b[0;32m   5541\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5547\u001b[0m     page_token: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PagedList[LoggedModel]:\n\u001b[0;32m   5549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5550\u001b[0m \u001b[38;5;124;03m    Search for logged models that match the specified search criteria.\u001b[39;00m\n\u001b[0;32m   5551\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5605\u001b[0m \u001b[38;5;124;03m        :py:class:`LoggedModel <mlflow.entities.LoggedModel>` objects.\u001b[39;00m\n\u001b[0;32m   5606\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_token\u001b[49m\n\u001b[0;32m   5609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:904\u001b[0m, in \u001b[0;36mTrackingServiceClient.search_logged_models\u001b[1;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_ids, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(eid, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m eid \u001b[38;5;129;01min\u001b[39;00m experiment_ids\n\u001b[0;32m    900\u001b[0m ):\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException\u001b[38;5;241m.\u001b[39minvalid_parameter_value(\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_ids must be a list of strings, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(experiment_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    903\u001b[0m     )\n\u001b[1;32m--> 904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_token\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:945\u001b[0m, in \u001b[0;36mRestStore.search_logged_models\u001b[1;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03mSearch for logged models that match the specified search criteria.\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m    :py:class:`LoggedModel <mlflow.entities.LoggedModel>` objects.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    921\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m    922\u001b[0m     SearchLoggedModels(\n\u001b[0;32m    923\u001b[0m         experiment_ids\u001b[38;5;241m=\u001b[39mexperiment_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m )\n\u001b[1;32m--> 945\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSearchLoggedModels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    946\u001b[0m models \u001b[38;5;241m=\u001b[39m [LoggedModel\u001b[38;5;241m.\u001b[39mfrom_proto(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mmodels]\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PagedList(models, response_proto\u001b[38;5;241m.\u001b[39mnext_page_token \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:134\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[0m\n\u001b[0;32m    132\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m    133\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:554\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[0;32m    551\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[0;32m    552\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[1;32m--> 554\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m response_to_parse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:308\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[1;32m--> 308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    311\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m         )\n",
      "\u001b[1;31mRestException\u001b[0m: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}"
     ]
    }
   ],
   "source": [
    "# Registramos el mejor modelo en MLflow\n",
    "# Id del run del RandonForest\n",
    "\n",
    "run_id = \"06e656762a774e97b8435a9a605ddc55\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# Registrar el modelo en MLflow Model Registry\n",
    "mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=\"RandomForest_10\"\n",
    ")\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "812ec1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd8076438d8433d91b019e315bee6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargamos el modelo directamente desde los artefactos del run (no desde Model Registry)\n",
    "import pickle\n",
    "\n",
    "# Usa el run_id del mejor modelo (por ejemplo, de la variable best_run o MODELO_REGISTRADO_INFO)\n",
    "run_id = \"06e656762a774e97b8435a9a605ddc55\"  # Puedes usar best_run.run_id si lo tienes din√°mico\n",
    "artifact_path = mlflow.artifacts.download_artifacts(f\"runs:/{run_id}/model\")\n",
    "model_file = artifact_path + \"/model.pkl\"\n",
    "\n",
    "with open(model_file, \"rb\") as f:\n",
    "\tmodel = pickle.load(f)\n",
    "\n",
    "# El modelo est√° listo para usar: model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c68317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 768.5264  713.5075  768.7331  753.5327  740.1118  734.7466  694.5313\n",
      "  747.4214  860.2902 1409.664  1500.501  1540.3167 1562.5022 1577.8163\n",
      " 1654.0649]\n"
     ]
    }
   ],
   "source": [
    "# Realizamos una predcci√≥n con el modelo cargado\n",
    "sample_data = X_test\n",
    "predictions = model.predict(sample_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd46b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 178.9245266666668\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el model cargado\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
