{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a696f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añade el directorio raíz del proyecto al sys.path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd32205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ENV HOPSWORKS_PROJECT_NAME: fleca_mlops\n",
      "DEBUG ENV PATH: C:\\Workspace\\mlops_fleca_project\\.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\mlops_fleca_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.data_utils import load_raw_data, transformar_a_series_temporales\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2086e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha actual: 2025-09-28 Sunday\n",
      "Última semana completa:\n",
      "  Lunes: 2025-09-15 Monday\n",
      "  Domingo: 2025-09-21 Sunday\n",
      "  Rango: 2025-09-15 a 2025-09-21\n"
     ]
    }
   ],
   "source": [
    "# 2. Calcular la última semana completa (lunes a domingo)\n",
    "\n",
    "hoy = datetime.utcnow()\n",
    "print(f\"Fecha actual: {hoy.strftime('%Y-%m-%d %A')}\")\n",
    "\n",
    "# Calcular cuántos días han pasado desde el lunes de esta semana\n",
    "dias_desde_lunes = hoy.weekday()  # 0=lunes, 1=martes, ..., 6=domingo\n",
    "\n",
    "# Ir al lunes de la semana pasada (última semana completa)\n",
    "ultimo_lunes = (hoy - timedelta(days=dias_desde_lunes + 7)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "ultimo_domingo = ultimo_lunes + timedelta(days=6)\n",
    "\n",
    "print(f\"Última semana completa:\")\n",
    "print(f\"  Lunes: {ultimo_lunes.strftime('%Y-%m-%d %A')}\")\n",
    "print(f\"  Domingo: {ultimo_domingo.strftime('%Y-%m-%d %A')}\")\n",
    "print(f\"  Rango: {ultimo_lunes.strftime('%Y-%m-%d')} a {ultimo_domingo.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81d706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos desde BigQuery porque descargar_bq=True o no existe el archivo C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting.parquet\n",
      "Iniciando conexión con BigQuery...\n",
      "Conexión establecida.\n",
      "Usando fechas en consulta SQL: fecha_inicio='2025-09-15' y fecha_fin='2025-09-21'\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n",
      "Ejecutando consulta SQL:\n",
      "\n",
      "    SELECT \n",
      "        fecha,\n",
      "        n_factura,\n",
      "        zona_de_venta,\n",
      "        producto,\n",
      "        familia,\n",
      "        cantidad,\n",
      "        base_imponible,\n",
      "        tipo_IVA,\n",
      "        total\n",
      "    FROM `fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023`\n",
      "    WHERE fecha >= '2025-09-15' AND fecha <= '2025-09-21'\n",
      "Conexión establecida.\n",
      "Usando fechas en consulta SQL: fecha_inicio='2025-09-15' y fecha_fin='2025-09-21'\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n",
      "Ejecutando consulta SQL:\n",
      "\n",
      "    SELECT \n",
      "        fecha,\n",
      "        n_factura,\n",
      "        zona_de_venta,\n",
      "        producto,\n",
      "        familia,\n",
      "        cantidad,\n",
      "        base_imponible,\n",
      "        tipo_IVA,\n",
      "        total\n",
      "    FROM `fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023`\n",
      "    WHERE fecha >= '2025-09-15' AND fecha <= '2025-09-21'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas descargadas de la segunda tabla: 2443\n",
      "Guardando archivo en C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250928.parquet ...\n",
      "Archivo guardado correctamente.\n",
      "Usando archivo recién generado: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250928.parquet\n",
      "Cargando datos desde: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250928.parquet\n",
      "Validando fechas entre 2025-09-15 y 2025-09-21 (7 días)\n",
      "Total de fechas faltantes: 0\n",
      "No faltan fechas en el rango especificado.\n",
      "Datos descargados: (2443, 11)\n"
     ]
    }
   ],
   "source": [
    "# 3. Descargar y cargar datos de BigQuery para esa semana\n",
    "df = load_raw_data(\n",
    "    fecha_inicio=ultimo_lunes.strftime('%Y-%m-%d'),\n",
    "    fecha_fin=ultimo_domingo.strftime('%Y-%m-%d'),\n",
    "    descargar_bq=True\n",
    ")\n",
    "print('Datos descargados:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882b4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series temporales generadas: (1, 8)\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    38  BOLLERIA          734.32               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-09-15  \n"
     ]
    }
   ],
   "source": [
    "# 4. Transformar a series temporales semanales solo para la familia BOLLERIA\n",
    "df_ts = transformar_a_series_temporales(df, familia=\"BOLLERIA\")\n",
    "print('Series temporales generadas:', df_ts.shape)\n",
    "print(df_ts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09cb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                       int64\n",
      "week                       int64\n",
      "familia           string[python]\n",
      "base_imponible           float64\n",
      "is_summer_peak             int32\n",
      "is_easter                  int64\n",
      "dias_semana                int64\n",
      "week_start        datetime64[ns]\n",
      "dtype: object\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    38  BOLLERIA          734.32               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-09-15  \n"
     ]
    }
   ],
   "source": [
    "# Eliminar columna 'fecha' si existe\n",
    "if 'fecha' in df_ts.columns:\n",
    "    df_ts = df_ts.drop(columns=['fecha'])\n",
    "\n",
    "# Ajustar tipos para coincidir con el schema del Feature Group histórico\n",
    "df_ts['year'] = df_ts['year'].astype('int64')  # bigint\n",
    "df_ts['week'] = df_ts['week'].astype('int64')  # bigint\n",
    "df_ts['familia'] = df_ts['familia'].astype('string')  # string\n",
    "df_ts['base_imponible'] = df_ts['base_imponible'].astype('float64')  # double\n",
    "df_ts['is_summer_peak'] = df_ts['is_summer_peak'].astype('int32')  # int\n",
    "df_ts['is_easter'] = df_ts['is_easter'].astype('int64')  # bigint\n",
    "df_ts['week_start'] = pd.to_datetime(df_ts['week_start'])  # timestamp\n",
    "\n",
    "print(df_ts.dtypes)\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5142035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-28 20:32:08,115 INFO: Initializing external client\n",
      "2025-09-28 20:32:08,116 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-09-28 20:32:08,116 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-28 20:32:09,239 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n"
     ]
    }
   ],
   "source": [
    "# 5. Conectar a hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=config.HOPSWORKS_API_KEY, \n",
    "    project=config.HOPSWORKS_PROJECT_NAME)\n",
    "\n",
    "# Conectar al feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# Conectar al Feature Group histórico\n",
    "try:\n",
    "    feature_group = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=config.FEATURE_GROUP_VERSION,\n",
    "        \n",
    "    )\n",
    "    if feature_group is None:\n",
    "        raise Exception(\"El Feature Group histórico no existe o el nombre/version no coinciden exactamente. Verifica en Hopsworks.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear/conectar el Feature Group: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f320788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semana a insertar: 2025-09-15 00:00:00\n",
      "year                       int64\n",
      "week                       int64\n",
      "familia           string[python]\n",
      "base_imponible           float64\n",
      "is_summer_peak             int32\n",
      "is_easter                  int64\n",
      "dias_semana                int64\n",
      "week_start        datetime64[ns]\n",
      "dtype: object\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    38  BOLLERIA          734.32               0          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-09-15  \n",
      "2025-09-28 20:32:17,970 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-09-28 20:32:17,972 INFO: Initializing external client\n",
      "2025-09-28 20:32:17,972 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-09-28 20:32:17,970 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-09-28 20:32:17,972 INFO: Initializing external client\n",
      "2025-09-28 20:32:17,972 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-28 20:32:19,296 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
      "Insertando 1 filas nuevas en el Feature Group.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
      "Insertando 1 filas nuevas en el Feature Group.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: times_series_bolleria_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/times_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/times_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "2025-09-28 20:32:37,328 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-09-28 20:32:37,328 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-09-28 20:32:40,600 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-09-28 20:32:40,600 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-09-28 20:32:43,820 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-09-28 20:32:43,820 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-09-28 20:34:23,404 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-09-28 20:34:23,404 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-09-28 20:34:23,561 INFO: Waiting for log aggregation to finish.\n",
      "2025-09-28 20:34:23,561 INFO: Waiting for log aggregation to finish.\n",
      "2025-09-28 20:34:38,920 INFO: Execution finished successfully.\n",
      "Inserción incremental realizada correctamente.\n",
      "2025-09-28 20:34:38,920 INFO: Execution finished successfully.\n",
      "Inserción incremental realizada correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Añadir solo la nueva semana al Feature Group histórico (evitando duplicados)\n",
    "from src.data_utils import transformar_a_series_temporales\n",
    "import pandas as pd\n",
    "\n",
    "# Supón que df contiene solo la última semana descargada\n",
    "df_ts = transformar_a_series_temporales(df, familia=\"BOLLERIA\")\n",
    "ultima_semana = df_ts['week_start'].max()\n",
    "print(f\"Semana a insertar: {ultima_semana}\")\n",
    "\n",
    "# --- FIX: Conversión explícita de tipos antes del insert ---\n",
    "# Eliminar columna 'fecha' si existe\n",
    "if 'fecha' in df_ts.columns:\n",
    "    df_ts = df_ts.drop(columns=['fecha'])\n",
    "# Ajustar tipos para coincidir con el schema del Feature Group histórico\n",
    "# (esto es CRÍTICO para evitar errores de tipo en Hopsworks)\n",
    "df_ts['year'] = df_ts['year'].astype('int64')  # bigint\n",
    "df_ts['week'] = df_ts['week'].astype('int64')  # bigint\n",
    "df_ts['familia'] = df_ts['familia'].astype('string')  # string\n",
    "df_ts['base_imponible'] = df_ts['base_imponible'].astype('float64')  # double\n",
    "df_ts['is_summer_peak'] = df_ts['is_summer_peak'].astype('int32')  # int (¡IMPORTANTE!)\n",
    "df_ts['is_easter'] = df_ts['is_easter'].astype('int64')  # bigint\n",
    "df_ts['week_start'] = pd.to_datetime(df_ts['week_start'])  # timestamp\n",
    "print(df_ts.dtypes)\n",
    "print(df_ts.head())\n",
    "# --- FIN FIX ---\n",
    "\n",
    "# Conectar a Hopsworks y al Feature Store\n",
    "from src.inference import conectar_hopsworks_feature_store\n",
    "import src.config as config\n",
    "proyecto, feature_store = conectar_hopsworks_feature_store()\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    ")\n",
    "\n",
    "# Leer semanas ya presentes en el Feature Group\n",
    "df_hopsworks = feature_group.read()\n",
    "semanas_existentes = set(df_hopsworks['week_start'].values)\n",
    "\n",
    "# Filtrar solo las filas de la nueva semana que no estén ya en Hopsworks\n",
    "nuevas_filas = df_ts[~df_ts['week_start'].isin(semanas_existentes)]\n",
    "if nuevas_filas.empty:\n",
    "    print(\"La semana ya existe en el Feature Group. No se inserta nada.\")\n",
    "else:\n",
    "    print(f\"Insertando {len(nuevas_filas)} filas nuevas en el Feature Group.\")\n",
    "    feature_group.insert(nuevas_filas, write_options={'wait_for_job': True})\n",
    "    print(\"Inserción incremental realizada correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-28 20:34:42,701 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-09-28 20:34:42,704 INFO: Initializing external client\n",
      "2025-09-28 20:34:42,705 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-09-28 20:34:42,704 INFO: Initializing external client\n",
      "2025-09-28 20:34:42,705 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-28 20:34:43,911 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobWarning: All jobs associated to feature view `times_series_bolleria_feature_view`, version `1` will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature View 'times_series_bolleria_feature_view' eliminado correctamente.\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/fs/1224799/fv/times_series_bolleria_feature_view/version/1\n",
      "Feature View 'times_series_bolleria_feature_view' creado y actualizado correctamente.\n",
      "Feature View de histórico actualizado correctamente.\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/fs/1224799/fv/times_series_bolleria_feature_view/version/1\n",
      "Feature View 'times_series_bolleria_feature_view' creado y actualizado correctamente.\n",
      "Feature View de histórico actualizado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Actualizar el Feature View de histórico tras insertar los datos en el Feature Group\n",
    "from src.inference import conectar_hopsworks_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# --- FUNCIÓN LOCAL: update_feature_view ---\n",
    "def update_feature_view(feature_store, fg_metadata, fv_metadata):\n",
    "    \"\"\"\n",
    "    Obtiene (o crea si no existe) el Feature View de histórico en Hopsworks.\n",
    "    fg_metadata: dict con 'name' y 'version' del Feature Group\n",
    "    fv_metadata: dict con 'name', 'version', 'description', 'labels', 'query' opcional\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fg = feature_store.get_feature_group(\n",
    "            name=fg_metadata['name'],\n",
    "            version=fg_metadata['version']\n",
    "        )\n",
    "        print(f\"Feature Group encontrado: {fg_metadata['name']} v{fg_metadata['version']}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"No se pudo obtener el Feature Group: {e}\")\n",
    "\n",
    "    # Si se pasa query personalizada, usarla; si no, usar fg.select_all()\n",
    "    if 'query' in fv_metadata and fv_metadata['query'] is not None:\n",
    "        query = fv_metadata['query']\n",
    "    else:\n",
    "        query = fg.select_all()\n",
    "\n",
    "    try:\n",
    "        # Intentar obtener el Feature View existente\n",
    "        fv = feature_store.get_feature_view(\n",
    "            name=fv_metadata['name'],\n",
    "            version=fv_metadata['version']\n",
    "        )\n",
    "        print(f\"Feature View encontrado: {fv_metadata['name']} v{fv_metadata['version']}. Ya existe, usando el existente.\")\n",
    "        print(\"Feature View verificado correctamente.\")\n",
    "    except Exception:\n",
    "        # Si no existe, crear uno nuevo\n",
    "        print(f\"Feature View {fv_metadata['name']} v{fv_metadata['version']} no existe. Creando uno nuevo...\")\n",
    "        try:\n",
    "            fv = feature_store.create_feature_view(\n",
    "                name=fv_metadata['name'],\n",
    "                version=fv_metadata['version'],\n",
    "                description=fv_metadata.get('description', ''),\n",
    "                labels=fv_metadata.get('labels', []),\n",
    "                query=query\n",
    "            )\n",
    "            print(\"Feature View creado correctamente.\")\n",
    "        except Exception as create_error:\n",
    "            # Si el error es que ya existe, obtenerlo\n",
    "            if \"already exists\" in str(create_error):\n",
    "                print(\"Feature View ya existe, obteniendo existente...\")\n",
    "                fv = feature_store.get_feature_view(\n",
    "                    name=fv_metadata['name'],\n",
    "                    version=fv_metadata['version']\n",
    "                )\n",
    "                print(\"Feature View obtenido correctamente.\")\n",
    "            else:\n",
    "                raise create_error\n",
    "\n",
    "# Conexión a Hopsworks\n",
    "proyecto, feature_store = conectar_hopsworks_feature_store()\n",
    "update_feature_view(\n",
    "    feature_store,\n",
    "    config.HISTORICAL_FEATURE_GROUP_METADATA,\n",
    "    config.HISTORICAL_FEATURE_VIEW_METADATA\n",
    " )\n",
    "print(\"Feature View de histórico actualizado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb24ce5",
   "metadata": {},
   "source": [
    "FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
