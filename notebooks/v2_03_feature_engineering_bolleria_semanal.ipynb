{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773ddaa7",
   "metadata": {},
   "source": [
    "# Presentaci√≥n del notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b480d56",
   "metadata": {},
   "source": [
    "**Feature Engineering para Predicci√≥n Semanal de Boller√≠a**\n",
    "\n",
    "Este notebook tiene como objetivo preparar el dataset final que ser√° utilizado para entrenar un modelo de predicci√≥n de ventas semanales en la categor√≠a **Boller√≠a**. Parte de los datos diarios ya validados y realiza todo el proceso de agregaci√≥n, enriquecimiento, generaci√≥n de variables temporales y preparaci√≥n de los conjuntos de datos `X` e `y`.\n",
    "\n",
    "\n",
    "\n",
    "üóÇÔ∏è Entradas\n",
    "- `validated_range_diario.parquet`: archivo diario con los datos corregidos, sin valores nulos, y con columnas de contexto como `is_weekend`, `is_easter`, `is_summer_peak`, etc.\n",
    "\n",
    "\n",
    "\n",
    "‚öôÔ∏è Proceso realizado\n",
    "\n",
    "1. **Filtrado por familia \"Boller√≠a\"** y selecci√≥n de variables clave (`fecha`, `base_imponible`, `total`, etc.).\n",
    "2. **Agregaci√≥n semanal** usando el lunes como primer d√≠a de la semana.\n",
    "3. **Asignaci√≥n precisa de la variable `is_easter`** usando fechas exactas de Semana Santa (no solo la ISO week).\n",
    "4. **C√°lculo de variables contextuales** a nivel semanal como:\n",
    "   - `is_summer_peak`: si hay alg√∫n d√≠a de verano \"pico\" en la semana.\n",
    "   - `is_easter`: si hay alg√∫n d√≠a de Semana Santa en la semana.\n",
    "5. **Generaci√≥n de variables lag** (`lag_1`, `lag_2`, `lag_3`, `lag_4`, `lag_12`, `lag_24`, `lag_52`) sobre la variable `base_imponible` para capturar patrones temporales semanales y anuales.\n",
    "6. **Eliminaci√≥n de filas con valores nulos** introducidos por los lags.\n",
    "7. **Selecci√≥n de variables de entrada (X) y target (y)** para el entrenamiento del modelo:\n",
    "   - **Features**: lags + variables contextuales (`is_summer_peak`, `is_easter`)\n",
    "   - **Target**: `base_imponible`\n",
    "8. **Exportaci√≥n final del dataset** a `ts_df_bolleria_baseline.parquet` listo para el entrenamiento del modelo.\n",
    "\n",
    "\n",
    "\n",
    "üì§ Salidas\n",
    "- `ts_df_bolleria_semanal.parquet`: serie semanal enriquecida (previa a aplicar lags).\n",
    "- `ts_df_bolleria_baseline.parquet`: dataset final con lags y sin nulos, listo para modelar.\n",
    "\n",
    "\n",
    "\n",
    "üìå Notas\n",
    "- La l√≥gica de `is_easter` se basa en las fechas exactas de Semana Santa, no en semanas ISO, para reflejar mejor el comportamiento real del negocio.\n",
    "- Los lags se calculan s√≥lo hacia el pasado (nunca con informaci√≥n futura).\n",
    "- Este notebook no entrena modelos, solo **deja todo listo para el siguiente paso: entrenamiento**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25846da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo ts_df_bolleria_semanal guardado en: ../data/processed\\ts_df_bolleria_semanal.parquet\n",
      "Comprobaci√≥n is_easter por a√±o: {np.uint32(2023): 1, np.uint32(2024): 1, np.uint32(2025): 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dateutil.easter import easter\n",
    "import os\n",
    "\n",
    "# 1. Carga del diario corregido\n",
    "df_diario = pd.read_parquet('../data/interim/validated_range_fecha_familia_20250630.parquet')\n",
    "df_diario['fecha'] = pd.to_datetime(df_diario['fecha'])\n",
    "\n",
    "# 2. Recalcular is_easter en el diario por si no estuviera:\n",
    "iso = df_diario['fecha'].dt.isocalendar()\n",
    "df_diario['year_iso'] = iso['year']\n",
    "df_diario['week_iso'] = iso['week']\n",
    "\n",
    "df_diario['is_easter'] = df_diario.apply(\n",
    "    lambda r: int(r['week_iso'] == easter(r['year_iso']).isocalendar()[1]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 3. Agregar a nivel semanal (todas las familias)\n",
    "df_semanal = (\n",
    "    df_diario\n",
    "      .groupby(['year_iso','week_iso','familia'], as_index=False)\n",
    "      .agg({\n",
    "         'base_imponible': 'sum',\n",
    "         'is_summer_peak': 'max',\n",
    "         'is_easter':      'max'\n",
    "      })\n",
    ")\n",
    "\n",
    "# 4. Filtrar solo BOLLERIA\n",
    "df_bolleria_semanal = df_semanal.query(\"familia=='BOLLERIA'\").copy()\n",
    "\n",
    "# 5. Renombrar columnas y ordenar\n",
    "df_bolleria_semanal.rename(columns={\n",
    "    'year_iso':'year',\n",
    "    'week_iso':'week'\n",
    "}, inplace=True)\n",
    "df_bolleria_semanal = df_bolleria_semanal.sort_values(['year','week']).reset_index(drop=True)\n",
    "\n",
    "# 6. Guardar en processed\n",
    "processed_dir = '../data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "out_path = os.path.join(processed_dir, 'ts_df_bolleria_semanal.parquet')\n",
    "df_bolleria_semanal.to_parquet(out_path, index=False)\n",
    "\n",
    "print(f\"Nuevo ts_df_bolleria_semanal guardado en: {out_path}\")\n",
    "print(\"Comprobaci√≥n is_easter por a√±o:\", df_bolleria_semanal.groupby('year')['is_easter'].sum().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a82c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (79, 9)\n",
      "Features ejemplo:\n",
      "    lag_1   lag_2   lag_3   lag_4      lag_12   lag_24  lag_52  \\\n",
      "0  789.71  534.79  563.18  806.54  912.130000  1745.97  825.11   \n",
      "1  571.14  789.71  534.79  563.18  750.990000  1681.41  658.40   \n",
      "2  572.51  571.14  789.71  534.79  821.840000  1753.02  741.40   \n",
      "3  597.65  572.51  571.14  789.71  895.391469  1835.18  653.64   \n",
      "4  680.30  597.65  572.51  571.14  743.259393  2127.71  680.46   \n",
      "\n",
      "   is_summer_peak  is_easter  \n",
      "0               0          0  \n",
      "1               0          0  \n",
      "2               0          0  \n",
      "3               0          0  \n",
      "4               0          0  \n",
      "Dataset de features guardado en: ../data/processed\\ts_bolleria_baseline.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Carga de la serie semanal procesada\n",
    "df = pd.read_parquet('../data/processed/ts_df_bolleria_semanal.parquet')\n",
    "\n",
    "# 2. Asegurar orden temporal\n",
    "df = df.sort_values(['year','week']).reset_index(drop=True)\n",
    "\n",
    "# 3. Definici√≥n de los lags a crear\n",
    "selected_lags = [1, 2, 3, 4, 12, 24, 52]\n",
    "\n",
    "# 4. Generar las columnas lag_X\n",
    "for lag in selected_lags:\n",
    "    df[f'lag_{lag}'] = df['base_imponible'].shift(lag)\n",
    "\n",
    "# 5. Eliminar filas con NaN (introducidas por los lags)\n",
    "df_features = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 6. Selecci√≥n de las columnas para el baseline\n",
    "feature_cols = [f'lag_{lag}' for lag in selected_lags] + ['is_summer_peak','is_easter']\n",
    "target_col   = 'base_imponible'\n",
    "\n",
    "X = df_features[feature_cols]\n",
    "y = df_features[target_col]\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Features ejemplo:\")\n",
    "print(X.head())\n",
    "\n",
    "# 7. (Opcional) Guardar este dataset listo para modelado\n",
    "out_dir = '../data/processed'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "df_features.to_parquet(os.path.join(out_dir,'ts_df_bolleria_baseline.parquet'), index=False)\n",
    "print(\"Dataset de features guardado en:\", os.path.join(out_dir,'ts_bolleria_baseline.parquet'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
