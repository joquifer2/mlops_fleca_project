{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd32205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.data_utils import load_raw_data, transformar_a_series_temporales\n",
    "from src import config\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Calcular la última semana completa\n",
    "\n",
    "hoy = datetime.utcnow()\n",
    "ultimo_lunes = (hoy - timedelta(days=hoy.weekday() + 7)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "ultimo_domingo = ultimo_lunes + timedelta(days=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a81d706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos desde BigQuery porque descargar_bq=True o no existe el archivo C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting.parquet\n",
      "Iniciando conexión con BigQuery...\n",
      "Conexión establecida.\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n",
      "Conexión establecida.\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas descargadas de la segunda tabla: 5362\n",
      "Guardando archivo en C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet ...\n",
      "Archivo guardado correctamente.\n",
      "Usando archivo recién generado: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet\n",
      "Cargando datos desde: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet\n",
      "Validando fechas entre 2025-08-04 y 2025-08-10 (7 días)\n",
      "Total de fechas faltantes: 0\n",
      "No faltan fechas en el rango especificado.\n",
      "Datos descargados: (3800, 11)\n"
     ]
    }
   ],
   "source": [
    "# 3. Descargar y cargar datos de BigQuery para esa semana\n",
    "df = load_raw_data(\n",
    "    fecha_inicio=ultimo_lunes.strftime('%Y-%m-%d'),\n",
    "    fecha_fin=ultimo_domingo.strftime('%Y-%m-%d'),\n",
    "    descargar_bq=True\n",
    ")\n",
    "print('Datos descargados:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series temporales generadas: (1, 8)\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    32  BOLLERIA         1609.03               1          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-08-04  \n"
     ]
    }
   ],
   "source": [
    "# 4. Transformar a series temporales semanales solo para la familia BOLLERIA\n",
    "df_ts = transformar_a_series_temporales(df, familia=\"BOLLERIA\")\n",
    "print('Series temporales generadas:', df_ts.shape)\n",
    "print(df_ts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c09cb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                       int64\n",
      "week                       int64\n",
      "familia           string[python]\n",
      "base_imponible           float64\n",
      "is_summer_peak             int32\n",
      "is_easter                  int64\n",
      "dias_semana                int64\n",
      "week_start        datetime64[ns]\n",
      "dtype: object\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    32  BOLLERIA         1609.03               1          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-08-04  \n"
     ]
    }
   ],
   "source": [
    "# Eliminar columna 'fecha' si existe\n",
    "if 'fecha' in df_ts.columns:\n",
    "    df_ts = df_ts.drop(columns=['fecha'])\n",
    "\n",
    "# Ajustar tipos para coincidir con el schema del Feature Group histórico\n",
    "df_ts['year'] = df_ts['year'].astype('int64')  # bigint\n",
    "df_ts['week'] = df_ts['week'].astype('int64')  # bigint\n",
    "df_ts['familia'] = df_ts['familia'].astype('string')  # string\n",
    "df_ts['base_imponible'] = df_ts['base_imponible'].astype('float64')  # double\n",
    "df_ts['is_summer_peak'] = df_ts['is_summer_peak'].astype('int32')  # int\n",
    "df_ts['is_easter'] = df_ts['is_easter'].astype('int64')  # bigint\n",
    "df_ts['week_start'] = pd.to_datetime(df_ts['week_start'])  # timestamp\n",
    "\n",
    "print(df_ts.dtypes)\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5142035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 12:57:22,463 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-08-15 12:57:22,466 INFO: Initializing external client\n",
      "2025-08-15 12:57:22,466 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-08-15 12:57:22,466 INFO: Initializing external client\n",
      "2025-08-15 12:57:22,466 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 12:57:23,601 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1242272\n"
     ]
    }
   ],
   "source": [
    "# 5. Conectar a hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=config.HOPSWORKS_API_KEY, \n",
    "    project=config.HOPSWORKS_PROJECT_NAME)\n",
    "\n",
    " # Conectar al feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    " # Conectar al Feature Group histórico\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    primary_key=[\"familia\", \"week_start\"],\n",
    "    event_time=\"week_start\"\n",
    ")\n",
    "if feature_group is None:\n",
    "    raise Exception(\"El Feature Group histórico no existe o el nombre/version no coinciden exactamente. Verifica en Hopsworks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f320788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/fs/1224799/fg/1498820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_bolleria_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1242272/jobs/named/time_series_bolleria_feature_group_1_offline_fg_materialization/executions\n",
      "2025-08-15 12:58:14,337 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-08-15 12:58:20,685 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-08-15 12:59:55,703 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-08-15 12:59:55,857 INFO: Waiting for log aggregation to finish.\n",
      "2025-08-15 13:00:04,460 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_bolleria_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insertar los datos en el Feature Group\n",
    "feature_group.insert(\n",
    "    df_ts,\n",
    "    write_options={'wait_for_job': True}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
