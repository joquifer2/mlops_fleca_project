{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd32205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from src.data_utils import load_raw_data, transformar_a_series_temporales\n",
    "from src import config\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2086e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calcular la última semana completa\n",
    "\n",
    "hoy = datetime.utcnow()\n",
    "ultimo_lunes = (hoy - timedelta(days=hoy.weekday() + 7)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "ultimo_domingo = ultimo_lunes + timedelta(days=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81d706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos desde BigQuery porque descargar_bq=True o no existe el archivo C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting.parquet\n",
      "Iniciando conexión con BigQuery...\n",
      "Conexión establecida.\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n",
      "Conexión establecida.\n",
      "Descargando datos de fleca-del-port.fleca_ventas_dia.t_facturas_dia_extendida_2023 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\mlops_fleca_project\\.venv\\lib\\site-packages\\google\\cloud\\bigquery\\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas descargadas de la segunda tabla: 5362\n",
      "Guardando archivo en C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet ...\n",
      "Archivo guardado correctamente.\n",
      "Usando archivo recién generado: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet\n",
      "Cargando datos desde: C:\\Workspace\\mlops_fleca_project\\data\\raw\\raw_data_bq_forecasting_20250815.parquet\n",
      "Validando fechas entre 2025-08-04 y 2025-08-10 (7 días)\n",
      "Total de fechas faltantes: 0\n",
      "No faltan fechas en el rango especificado.\n",
      "Datos descargados: (3800, 11)\n",
      "Validando fechas entre 2025-08-04 y 2025-08-10 (7 días)\n",
      "Total de fechas faltantes: 0\n",
      "No faltan fechas en el rango especificado.\n",
      "Datos descargados: (3800, 11)\n"
     ]
    }
   ],
   "source": [
    "# 3. Descargar y cargar datos de BigQuery para esa semana\n",
    "df = load_raw_data(\n",
    "    fecha_inicio=ultimo_lunes.strftime('%Y-%m-%d'),\n",
    "    fecha_fin=ultimo_domingo.strftime('%Y-%m-%d'),\n",
    "    descargar_bq=True\n",
    ")\n",
    "print('Datos descargados:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882b4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series temporales generadas: (1, 8)\n",
      "   year  week   familia  base_imponible  is_summer_peak  is_easter  \\\n",
      "0  2025    32  BOLLERIA         1609.03               1          0   \n",
      "\n",
      "   dias_semana week_start  \n",
      "0            7 2025-08-04  \n"
     ]
    }
   ],
   "source": [
    "# 4. Transformar a series temporales semanales solo para la familia BOLLERIA\n",
    "df_ts = transformar_a_series_temporales(df, familia=\"BOLLERIA\")\n",
    "print('Series temporales generadas:', df_ts.shape)\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna 'fecha' para el Feature Group\n",
    "df_ts['fecha'] = df_ts['week_start']\n",
    "print(df_ts.columns)\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5142035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=config.HOPSWORKS_API_KEY, \n",
    "    project=config.HOPSWORKS_PROJECT_NAME)\n",
    "\n",
    " # Conectar al feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    " # Conectar al Feature Group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    description=\"Feature group for BOLLERIA weekly time series\",\n",
    "    primary_key=[\"fecha\", \"familia\"],\n",
    "    event_time=\"fecha\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f320788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar los datos en el Feature Group\n",
    "feature_group.insert(\n",
    "    df_ts,\n",
    "    write_options={'wait_for_job': True}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
