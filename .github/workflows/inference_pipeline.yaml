name: Fleca MLOps Inference Pipeline

on:
  schedule:
    - cron: '20 18 * * 2'  # Cada martes a las 18:10 (UTC)
  workflow_dispatch:

jobs:
  inference_pipeline:
    runs-on: ubuntu-latest
    steps:
      # 1. Descargar el código del repositorio
      - name: Checkout repository
        uses: actions/checkout@v2

      # 2. Instalar Python y Poetry
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Install Poetry manually
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          export PATH="$HOME/.local/bin:$PATH"

      # 3. Instalar las dependencias del proyecto
      - name: Install project dependencies
        run: |
          poetry config virtualenvs.in-project true
          poetry install --no-interaction --no-ansi

      # 4. Guardar el archivo de credenciales de Google Cloud en el runner
      - name: Write Google credentials to file
        run: |
          cat <<EOF > /tmp/credentials.json
          ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
          EOF

      # 5. Configurar la variable de entorno para que las librerías encuentren el archivo
      - name: Set GOOGLE_APPLICATION_CREDENTIALS env
        run: echo "GOOGLE_APPLICATION_CREDENTIALS=/tmp/credentials.json" >> $GITHUB_ENV

      # 6. Ejecutar el pipeline de inferencia (notebook)
      - name: Run inference pipeline notebook
        env:
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT_NAME: ${{ secrets.HOPSWORKS_PROJECT_NAME }}
        run: |
          poetry run jupyter nbconvert --to notebook --execute notebooks/15_inference_pipeline.ipynb --inplace

      # 7. (opcional) Subir el notebook ejecutado como artefacto para poder revisarlo
      - name: Upload executed notebook
        uses: actions/upload-artifact@v4
        with:
          name: executed-inference-pipeline-notebook
          path: notebooks/15_inference_pipeline.ipynb
